<!-- Generated by SpecStory, Markdown v2.0.0 -->

<!-- cursor Session 22f687b8-6b2c-4063-b507-0edb8bf4c4c4 (2025-11-06 20:56Z) -->

# Check official docs and virtual environment (2025-11-06 20:56Z)

_**User (2025-11-06 20:41Z)**_

@04-agno-agentos.py (307)  



look at the official docs. Confirm you are using the right virtual env

---

_**Agent (model claude-4.5-sonnet-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is asking me to:
1. Look at the official docs for AgentOS
2. Confirm that the right virtual environment is being used

Let me first read the file they're referencing (04-agno-agentos.py) and then check the official docs they have in the agentos-reference folder. I should also check what virtual environment is currently set up.

Let me start by reading the relevant files to understand the context.</details></think>

---

I'll check the official AgentOS docs and verify the virtual environment setup.

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: 04-agno-agentos.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: agentos-reference/README.md</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: agentos-reference/GETTING_STARTED.md</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: requirements-agentos.txt</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to look at the virtual environment setup. The user is asking me to confirm they're using the right virtual environment. Looking at the project structure, I can see there's a `venv\` folder in the workspace.

Let me check the documentation to see what the correct virtual environment should be. According to the GETTING_STARTED.md:

Line 113-118:
```bash
# Activate virtual environment
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Install AgentOS packages
pip install -r requirements-agentos.txt
```

The documentation says `.venv` but the project structure shows `venv\`. This could be the issue!

Also, looking at line 124 of the guide, it says:
```bash
python agentos_integration.py
```

But the actual file is named `04-agno-agentos.py`, not `agentos_integration.py`.

Let me check the start scripts to see what they're configured to do.</details></think>

---

Let me check the start scripts and verify the virtual environment setup:

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: start-agentos.sh</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: start-agentos.bat</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Perfect! Now I can see the issue. Looking at the start scripts:

**start-agentos.sh (Lines 84-93):**
```bash
if [ -d ".venv" ]; then
    VENV_DIR=".venv"
elif [ -d "venv" ]; then
    VENV_DIR="venv"
else
    echo -e "${BLUE}ðŸ“¦ Creating virtual environment...${NC}"
    python -m venv .venv
    VENV_DIR=".venv"
```

**start-agentos.bat (Lines 74-83):**
```batch
if exist .venv (
    set VENV_DIR=.venv
) else if exist venv (
    set VENV_DIR=venv
) else (
    echo ðŸ“¦ Creating virtual environment...
    python -m venv .venv
    set VENV_DIR=.venv
```

Both scripts check for BOTH `.venv` and `venv` directories and will use whichever exists. However, the official documentation recommends `.venv` (with a dot). 

The project structure shows:
```
venv\
  - Include\
  - Lib\
    - site-packages\
      - pip\
```

So they currently have `venv\` (no dot), but the documentation and scripts both prefer `.venv` (with dot).

Key findings:
1. The scripts are **flexible** - they check for both `.venv` and `venv` and will use whichever exists
2. The official Agno docs recommend `.venv` (standard Python convention)
3. Currently they have `venv` (without dot)
4. Both will work, but `.venv` is the convention

The scripts will work correctly either way. Since they already have `venv\`, the script will detect and use it.

However, I should confirm that they're using the right virtual environment by checking if the AgentOS dependencies are installed in it.</details></think>

---

## Virtual Environment Analysis

Looking at the official AgentOS documentation and your current setup:

### What the Official Docs Say

From `GETTING_STARTED.md` lines 113-118:
```bash
# Activate virtual environment
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

The official documentation recommends **`.venv`** (with a dot).

### What Your Scripts Do

Both `start-agentos.sh` (lines 84-93) and `start-agentos.bat` (lines 74-83) are **flexible**:

```bash
# They check for BOTH and use whichever exists:
if [ -d ".venv" ]; then
    VENV_DIR=".venv"
elif [ -d "venv" ]; then
    VENV_DIR="venv"
```

### Your Current Setup

You have `venv\` (without dot) in your project root.

### Verdict: âœ… You're Fine

**Your setup will work** - the scripts detect and use either `venv` or `.venv`. However:

- **Standard Python convention** is `.venv` (with dot)
- **Git typically ignores** `.venv` by default
- **Agno's official examples** use `.venv`

### Recommendation

You have two options:

**Option 1: Keep using `venv` (no change needed)**
- Your scripts already handle this
- Will work perfectly

**Option 2: Switch to `.venv` for consistency**
```bash
# Rename the directory
mv venv .venv

# Or delete and let the script recreate it
rm -rf venv
bash start-agentos.sh  # Will create .venv automatically
```

Either way, just make sure you're activating the correct one when running manually:
```bash
# Windows (your system)
venv\Scripts\activate     # Current setup
# or
.venv\Scripts\activate    # If you switch
```

The scripts handle both automatically, so your choice!

---

_**User (2025-11-06 20:41Z)**_

 

---

_**Agent (model claude-4.5-sonnet-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is pointing me to line 307 of 04-agno-agentos.py again. Let me look at what's around that line to understand the context better. They previously asked me to look at the official docs and confirm the right virtual env, which I just did. Now they're pointing back to line 307 of the file.

Let me look at line 307 more carefully in the context I already have from the file:

```python
move_decision_team = Team(
    name="City Move Decision Team",
    team_id="move-decision-team",  # Unique ID for AgentOS  <- line 317
    model=OpenAIChat("gpt-4o-mini"),
    members=[cost_analyst, sentiment_analyst, migration_researcher],
    ...
```

Wait, looking back at my previous read_file output, line 317 has</details></think>

---

_**User (2025-11-06 20:41Z)**_

ModuleNotFoundError: No module named 'agno.storage'

(.venv)

ahmed@TheMountain MINGW64 /c/CodeWork/should-i-move (main)

$ python 04-agno-agentos.py 

Traceback (most recent call last):

  File "C:\CodeWork\should-i-move\04-agno-agentos.py", line 32, in <module>

    from agno.storage.agent.postgres import PgAgentStorage

ModuleNotFoundError: No module named 'agno.storage'

(.venv) 

---

_**Agent (model claude-4.5-sonnet-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is getting `ModuleNotFoundError: No module named 'agno.storage'` when running the AgentOS integration script. They're using `.venv` now (as shown in the prompt).

Let me check what the actual Agno package structure is. The error suggests that the import path might be wrong. Let me look at the official docs to see what the correct import should be.

Looking at the code in `04-agno-agentos.py`, I see:
- Line 32: `from agno.storage.agent.postgres import PgAgentStorage`
- Line 34: `from agno.memory.db.postgres import PgMemoryDb`
- Line 35: `from agno.vectordb.pgvector import PgVector`

This might be using an outdated API. I should search for the correct import paths in the official Agno documentation.

Let me check the official Agno docs to see what the correct imports should be.</details></think>

---

The issue is that the import paths in `04-agno-agentos.py` are using outdated Agno API. Let me check the official Agno documentation for the correct imports:

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_docs-agno_SearchAgno">
<details>
          <summary>Tool use: **mcp_docs-agno_SearchAgno**</summary>
      
*Called tool*: docs-agno - SearchAgno: Search across the Agno knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Agno, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation pages.

*Parameters*:
  * query: AgentOS storage postgres import PgAgentStorage

*Result*:
Title: Postgres for Agent
Link: https://docs.agno.com/examples/concepts/db/postgres/postgres_for_agent
Content: Agno supports using PostgreSQL as a storage backend for Agents using the PostgresDb class.

Postgres for Agent
Agno supports using PostgreSQL as a storage backend for Agents using the PostgresDb class.

Run PgVector
Install docker desktop and run PgVector on port 5532 using: from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

agent = Agent(
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")



*Result*:
Title: Agent with Storage
Link: https://docs.agno.com/examples/models/groq/storage
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.groq import Groq
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.groq import Groq
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Usage
Set your API key Install libraries Run PgVector docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16



*Result*:
Title: Agent with Storage
Link: https://docs.agno.com/examples/models/gemini/storage
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-001"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-001"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Usage
Set your API key Install libraries Run PgVector docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16



*Result*:
Title: Agent with Storage
Link: https://docs.agno.com/examples/models/azure/ai_foundry/storage
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.azure import AzureAIFoundry
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=AzureAIFoundry(id="Phi-4"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.azure import AzureAIFoundry
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=AzureAIFoundry(id="Phi-4"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Usage
Set your API key Install libraries Run PgVector docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16



*Result*:
Title: Agent with Storage
Link: https://docs.agno.com/examples/models/cerebras_openai/storage
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.cerebras import CerebrasOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=CerebrasOpenAI(id="llama-4-scout-17b-16e-instruct"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.cerebras import CerebrasOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=CerebrasOpenAI(id="llama-4-scout-17b-16e-instruct"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Usage
Set your API key Install libraries Run Agent python cookbook/models/cerebras_openai/db.py



*Result*:
Title: Agent with Storage
Link: https://docs.agno.com/examples/models/nebius/storage
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.nebius import Nebius
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Nebius(),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.nebius import Nebius
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Nebius(),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Usage
Set your API key Install libraries Run PgVector docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16



*Result*:
Title: Agent with Storage
Link: https://docs.agno.com/examples/models/aws/bedrock/storage
Content: Code
from agno.agent import Agent
from agno.models.aws import AwsBedrock
from agno.db.postgres import PostgresDb
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"),
    db=PostgresDb(session_table="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Code
from agno.agent import Agent
from agno.models.aws import AwsBedrock
from agno.db.postgres import PostgresDb
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"),
    db=PostgresDb(session_table="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Usage
Set your AWS Credentials Install libraries Run PgVector docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16



*Result*:
Title: Agent with Storage
Link: https://docs.agno.com/examples/models/cohere/storage
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.cohere import Cohere
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Cohere(id="command-a-03-2025"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.cohere import Cohere
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Cohere(id="command-a-03-2025"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Usage
Set your API key Install libraries Run PgVector docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16



*Result*:
Title: PostgresDb
Link: https://docs.agno.com/reference/storage/postgres
Content: PostgresDb is a class that implements the Db interface using PostgreSQL as the backend storage system. It provides robust, relational storage for agent sessions with support for JSONB data types, schema versioning, and efficient querying.

PostgresDb
PostgresDb is a class that implements the Db interface using PostgreSQL as the backend storage system. It provides robust, relational storage for agent sessions with support for JSONB data types, schema versioning, and efficient querying.



*Result*:
Title: Agent with Storage
Link: https://docs.agno.com/examples/models/openai/chat/storage
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

Usage
Set your API key Install libraries Run PgVector docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16


</details>
</tool-use>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_docs-agno_SearchAgno">
<details>
          <summary>Tool use: **mcp_docs-agno_SearchAgno**</summary>
      
*Called tool*: docs-agno - SearchAgno: Search across the Agno knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Agno, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation pages.

*Parameters*:
  * query: create_agentos_app FastAPI example

*Result*:
Title: Create Your First AgentOS
Link: https://docs.agno.com/agent-os/creating-your-first-os
Content: Get started with AgentOS by setting up a minimal local instance.
This guide will have you running your first agent in minutes, with optional paths to add advanced features through our examples. AgentOS is a FastAPI app that you can run locally or in your cloud. If you want to build AgentOS using an existing FastAPI app, check out the Custom FastAPI App guide.

Quick setup guide to get your first AgentOS instance running locally

Minimal Setup
Create my_os.py: from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os import AgentOS

assistant = Agent(
    name="Assistant",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=["You are a helpful AI assistant."],
    markdown=True,
)

agent_os = AgentOS(
    id="my-first-os",
    description="My first AgentOS",
    agents=[assistant],
)

app = agent_os.get_app()

if __name__ == "__main__":
    # Default port is 7777; change with port=...
    agent_os.serve(app="my_os:app", reload=True)



*Result*:
Title: Bring Your Own FastAPI App
Link: https://docs.agno.com/agent-os/customize/custom-fastapi
Content: AgentOS is built on FastAPI, which means you can easily integrate your existing FastAPI applications or add custom routes and routers to extend your agent's capabilities.

Learn how to use your own FastAPI app in your AgentOS

Quick Start
The simplest way to bring your own FastAPI app is to pass it to the AgentOS constructor: Your custom FastAPI app can have its own middleware and dependencies. If you have your own CORS middleware, it will be updated to include the AgentOS allowed origins, to make the AgentOS instance compatible with the Control Plane.
If not then the appropriate CORS middleware will be added to the app.



*Result*:
Title: Custom FastAPI App with JWT Middleware
Link: https://docs.agno.com/examples/agent-os/middleware/custom-fastapi-jwt
Content: This example demonstrates how to integrate JWT middleware with your custom FastAPI application and then add AgentOS functionality on top.

Custom FastAPI application with JWT middleware for authentication and AgentOS integration

Code
from datetime import datetime, timedelta, UTC

import jwt
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.os.middleware import JWTMiddleware
from agno.tools.duckduckgo import DuckDuckGoTools
from fastapi import FastAPI, Form, HTTPException

# JWT Secret (use environment variable in production)
JWT_SECRET = "a-string-secret-at-least-256-bits-long"

# Setup database
db = PostgresDb(db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

# Create agent
research_agent = Agent(
    id="research-agent",
    name="Research Agent",
    model=OpenAIChat(id="gpt-4o"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
    markdown=True,
)

# Create custom FastAPI app
app = FastAPI(
    title="Example Custom App",
    version="1.0.0",
)

# Add Agno JWT middleware to your custom FastAPI app
app.add_middleware(
    JWTMiddleware,
    secret_key=JWT_SECRET,
    excluded_route_paths=[
        "/auth/login"
    ],  # We don't want to validate the token for the login endpoint
    validate=True,  # Set validate to False to skip token validation
)


# Custom routes that use JWT
@app.post("/auth/login")
async def login(username: str = Form(...), password: str = Form(...)):
    """Login endpoint that returns JWT token"""
    if username == "demo" and password == "password":
        payload = {
            "sub": "user_123",
            "username": username,
            "exp": datetime.now(UTC) + timedelta(hours=24),
            "iat": datetime.now(UTC),
        }
        token = jwt.encode(payload, JWT_SECRET, algorithm="HS256")
        return {"access_token": token, "token_type": "bearer"}

    raise HTTPException(status_code=401, detail="Invalid credentials")


# Clean AgentOS setup with tuple middleware pattern! âœ¨
agent_os = AgentOS(
    description="JWT Protected AgentOS",
    agents=[research_agent],
    base_app=app,
)

# Get the final app
app = agent_os.get_app()

if __name__ == "__main__":
    """
    Run your AgentOS with JWT middleware applied to the entire app.

    Test endpoints:
    1. POST /auth/login - Login to get JWT token
    2. GET /config - Protected route (requires JWT)
    """
    agent_os.serve(
        app="custom_fastapi_jwt:app", port=7777, reload=True
    )



*Result*:
Title: AgentOS Parameters
Link: https://docs.agno.com/agent-os/customize/os/attributes
Content: You can configure the behaviour of your AgentOS by passing the following parameters to the AgentOS class: agents : List of agents to include in the AgentOS teams : List of teams to include in the AgentOS workflows : List of workflows to include in the AgentOS knowledge : List of knowledge instances to include in the AgentOS interfaces : List of interfaces to include in the AgentOS See the Interfaces section for more details. config : Configuration file path or AgentOSConfig instance See the Configuration page for more details. base_app : Optional custom FastAPI app to use instead of creating a new one See the Custom FastAPI App page for more details. lifespan : Optional lifespan context manager for the FastAPI app See the Lifespan page for more details. enable_mcp_server : Turn your AgentOS into an MCP server See the MCP enabled AgentOS page for more details. on_route_conflict : Optionally preserve your custom routes over AgentOS routes (set to "preserve_base_app" ). Defaults to "preserve_agentos" , preserving the AgentOS routes See the Overriding Routes page for more details. See the AgentOS class reference for more details.

Learn about the attributes of the AgentOS class



*Result*:
Title: Adding Middleware to AgentOS
Link: https://docs.agno.com/agent-os/customize/middleware/custom
Content: Create AgentOS App Add Custom Middleware Serve your AgentOS See the following full examples: Custom Middleware Custom FastAPI + JWT

Creating Custom Middleware
Custom middleware in AgentOS follows the FastAPI/Starlette middleware pattern using BaseHTTPMiddleware: from starlette.middleware.base import BaseHTTPMiddleware
from fastapi import Request, Response

class CustomMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, param1: str = "default"):
        super().__init__(app)
        self.param1 = param1

    async def dispatch(self, request: Request, call_next) -> Response:
        # Before request processing
        start_time = time.time()
        
        # Process request
        response = await call_next(request)
        
        # After request processing  
        process_time = time.time() - start_time
        response.headers["X-Process-Time"] = str(process_time)
        
        return response

Creating Custom Middleware
Custom middleware in AgentOS follows the FastAPI/Starlette middleware pattern using BaseHTTPMiddleware:



*Result*:
Title: undefined
Link: https://docs.agno.com/
Content: 

*Result*:
Title: AgentOS + MCPTools
Link: https://docs.agno.com/agent-os/mcp/tools
Content: Model Context Protocol (MCP) gives Agents the ability to interact with external systems through a standardized interface. You can give your agents access to tools from MCP servers using MCPTools. When using MCPTools within AgentOS, the lifecycle is automatically managed. No need to manually connect or disconnect the MCPTools instance. This does not automatically refresh connections that are interrupted or restarted, you can use refresh_connection to do so. If you are using MCPTools within AgentOS, you should not use reload=True when serving your AgentOS.
This can break the MCP connection during the FastAPI lifecycle. See here for a full example.

Model Context Protocol (MCP) gives Agents the ability to interact with external systems through a standardized interface. You can give your agents access to tools from MCP servers using MCPTools. When using MCPTools within AgentOS, the lifecycle is automatically managed. No need to manually connect or disconnect the MCPTools instance. from agno.agent import Agent
from agno.os import AgentOS
from agno.tools.mcp import MCPTools

# Create MCPTools instance
mcp_tools = MCPTools(
    transport="streamable-http", 
    url="https://docs.agno.com/mcp"
)

# Create MCP-enabled agent
agent = Agent(
    id="agno-agent",
    name="Agno Agent",
    tools=[mcp_tools],
)

# AgentOS manages MCP lifespan
agent_os = AgentOS(
    description="AgentOS with MCP Tools",
    agents=[agent],
)

app = agent_os.get_app()

if __name__ == "__main__":
    # Don't use reload=True with MCP tools to avoid lifespan issues
    agent_os.serve(app="mcp_tools_example:app")

Learn how to use MCPTools in your AgentOS



*Result*:
Title: What is the AgentOS?
Link: https://docs.agno.com/introduction
Content: AgentOS is a high-performance runtime for multi-agent systems. Key features include: Pre-built FastAPI runtime : AgentOS ships with a ready-to-use FastAPI app for orchestrating your agents, teams, and workflows. This gives you a major head start in building your AI product. Integrated Control Plane : The AgentOS UI connects directly to your runtime, letting you test, monitor, and manage your system in real time. This gives you unmatched visibility and control over your system. Private by Design : AgentOS runs entirely in your cloud, ensuring complete data privacy. No data ever leaves your system. This is ideal for security-conscious enterprises. Here's what the AgentOS UI looks like in action:

The Complete Agentic Solution
For companies building agents, Agno provides the complete solution: The fastest framework for building agents, multi-agent teams and agentic workflows. A ready-to-use FastAPI app that gets you building AI products on day one. A control plane for testing, monitoring and managing your system. We bring a novel architecture that no other framework provides, your AgentOS runs securely in your cloud, and the control plane connects directly to it from your browser. You don't need to send data to any external services or pay retention costs, you get complete privacy and control.

What is Agno?
Use it to build multi-agent systems with memory, knowledge, human in the loop and MCP support. You can orchestrate agents as multi-agent teams (more autonomy) or step-based agentic workflows (more control). Hereâ€™s an example of an Agent that connects to an MCP server, manages conversation state in a database, and is served using a FastAPI application that you can interact with using the AgentOS UI. from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.tools.mcp import MCPTools

# ************* Create Agent *************
agno_agent = Agent(
    name="Agno Agent",
    model=Claude(id="claude-sonnet-4-5"),
    db=SqliteDb(db_file="agno.db"),
    tools=[MCPTools(transport="streamable-http", url="https://docs.agno.com/mcp")],
    add_history_to_context=True,
    markdown=True,
)

# ************* Create AgentOS *************
agent_os = AgentOS(agents=[agno_agent])
app = agent_os.get_app()

# ************* Run AgentOS *************
if __name__ == "__main__":
    agent_os.serve(app="agno_agent:app", reload=True)



*Result*:
Title: AgentOS API
Link: https://docs.agno.com/agent-os/api
Content: AgentOS is a RESTful API that provides access to your agentic system. It allows you to: Run Agents / Teams / Workflows : Create new runs for your agents, teams and workflows, either with a new session or a existing one. Manage Sessions : Retrieve, update and delete sessions. Manage Memories : Retrieve, update and delete memories. Manage Knowledge : Manage the content of your knowledge base. Manage Evals : Retrieve, create, delete and update evals. This is the same API that powers the AgentOS Control Plane. However, the same endpoints can be used to power your own application! See the full API reference for more details.

Passing agent parameters
Agent, Team and Workflow run() and arun() endpoints all support additional parameters. See the Agent arun schema , Team arun schema , Workflow arun schema for more details. To pass these parameters to your agent, team or workflow, via the , you can simply specify them as form-based parameters. Below is an example where dependencies are passed to the agent: from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.os import AgentOS

# Setup the database
db = PostgresDb(id="basic-db", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

# Setup basic agents, teams and workflows
story_writer = Agent(
    id="story-writer-agent",
    name="Story Writer Agent",
    db=db,
    markdown=True,
    instructions="You are a story writer. You are asked to write a story about a robot. Always name the robot {robot_name}",
)

# Setup our AgentOS app
agent_os = AgentOS(
    description="Example AgentOS to show how to pass dependencies to an agent",
    agents=[story_writer],
)
app = agent_os.get_app()


if __name__ == "__main__":
    agent_os.serve(app="dependencies_to_agent:app", reload=True)

Learn how to use the AgentOS API to interact with your agentic system



*Result*:
Title: Agent Infra Docker
Link: https://docs.agno.com/templates/agent-infra-docker/introduction
Content: The Agent Infra Docker template provides a simple Docker Compose file for running AgentOS. It contains: An AgentOS instance, serving Agents, Teams, Workflows and utilities using FastAPI. A PostgreSQL database for storing sessions, memories and knowledge. After creating your codebase, the next step is to get it up and running locally using docker

Agent Infra Docker
The Agent Infra Docker template provides a simple Docker Compose file for running AgentOS. It contains: An AgentOS instance, serving Agents, Teams, Workflows and utilities using FastAPI. A PostgreSQL database for storing sessions, memories and knowledge. After creating your codebase, the next step is to get it up and running locally using docker


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Perfect! Now I can see the correct import structure from the official Agno docs. The correct imports are:

1. `from agno.db.postgres import PostgresDb` (not `agno.storage.agent.postgres`)
2. There's no separate memory db class - it's all handled by the `db` parameter on Agent
3. Knowledge uses `from agno.knowledge.text import TextKnowledgeBase` 
4. Vector DB uses `from agno.vectordb.pgvector import PgVector`

The key thing is: the current code uses outdated API paths. I need to fix the imports and restructure to use the new AgentOS API with `AgentOS` class instead of `create_agentos_app`.

Let me update the file to use the correct modern Agno API structure.</details></think>

---

Found the issue! The code is using **outdated Agno API imports**. The official docs show a completely different structure. Let me fix the imports and update to the modern AgentOS API:

**Plan:**
1. Replace outdated `agno.storage` imports with `agno.db.postgres`
2. Update to use `AgentOS` class instead of `create_agentos_app`
3. Simplify the database setup - single `PostgresDb` handles sessions and memory
4. Update knowledge base and vector DB setup

**Fixing the code:**

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 2

```diff
@@ -30,7 +30,6 @@
  from agno.tools.firecrawl import FirecrawlTools
  from agno.tools.local_file_system import LocalFileSystemTools
- from agno.storage.agent.postgres import PgAgentStorage
+ from agno.db.postgres import PostgresDb
  from agno.knowledge.text import TextKnowledgeBase
- from agno.memory.db.postgres import PgMemoryDb
  from agno.vectordb.pgvector import PgVector
  from pydantic import BaseModel, Field
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to update the database configuration section to use the new PostgresDb class. Let me continue with the changes.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 2, lines removed: 8

```diff
@@ -49,15 +49,9 @@
  DB_URL = os.getenv(&quot;AGENTOS_DB_URL&quot;, &quot;postgresql+psycopg://agno:agno@localhost:5532/agno&quot;)
  
- # Configure storage for session management
- agent_storage = PgAgentStorage(
+ # Configure database for session and memory management
+ db = PostgresDb(
      table_name=&quot;agent_sessions&quot;,
      db_url=DB_URL,
  )
- 
- # Configure memory database for persistent memory across sessions
- memory_db = PgMemoryDb(
-     table_name=&quot;agent_memory&quot;,
-     db_url=DB_URL,
- )
  
  # Configure vector database for knowledge base
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Good, now I need to update the agents to use the new `db` parameter instead of separate `storage` and `memory` parameters.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 2

```diff
@@ -249,6 +249,5 @@
      tools=[get_cost_of_living_comparison],
      output_schema=CostAnalysis,
-     storage=agent_storage,  # Enable session storage
-     memory=memory_db,  # Enable memory persistence
+     db=db,  # Enable session storage and memory
      knowledge=relocation_knowledge,  # Attach knowledge base
      markdown=True,
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to update the sentiment_analyst and migration_researcher agents with the same changes.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 2

```diff
@@ -270,6 +270,5 @@
      ],
      output_schema=SentimentAnalysis,
-     storage=agent_storage,  # Enable session storage
-     memory=memory_db,  # Enable memory persistence
+     db=db,  # Enable session storage and memory
      knowledge=relocation_knowledge,  # Attach knowledge base
      markdown=True,
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now update the migration_researcher agent.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 2

```diff
@@ -293,6 +293,5 @@
      tools=[search_reddit_discussions],
      output_schema=MigrationInsights,
-     storage=agent_storage,  # Enable session storage
-     memory=memory_db,  # Enable memory persistence
+     db=db,  # Enable session storage and memory
      knowledge=relocation_knowledge,  # Attach knowledge base
      markdown=True,
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to update the Team configuration as well.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 2

```diff
@@ -338,6 +338,5 @@
      ],
      output_schema=FinalRecommendation,
-     storage=agent_storage,  # Enable session storage
-     memory=memory_db,  # Enable memory persistence
+     db=db,  # Enable session storage and memory
      knowledge=relocation_knowledge,  # Attach knowledge base
      add_member_tools_to_context=False,
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to update the FastAPI application creation. The official docs show using `AgentOS` class instead of `create_agentos_app`. Let me update that section.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 9, lines removed: 5

```diff
@@ -350,13 +350,17 @@
  # ============================================================================
  
- from agno.api.app import create_agentos_app
- 
- # Create the AgentOS FastAPI application
- app = create_agentos_app(
+ from agno.os import AgentOS
+ 
+ # Create the AgentOS instance
+ agent_os = AgentOS(
+     id=&quot;should-i-move-os&quot;,
+     description=&quot;Should I Move? - City Relocation Analysis System&quot;,
      agents=[cost_analyst, sentiment_analyst, migration_researcher],
      teams=[move_decision_team],
      knowledge=[relocation_knowledge],
-     storage=agent_storage,
  )
+ 
+ # Get the FastAPI app
+ app = agent_os.get_app()
  
  
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>




Now update the server startup code to use the new agent_os.serve() method.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: undefined, lines removed: 2

```diff
@@ -370,6 +370,4 @@
  
  if __name__ == &quot;__main__&quot;:
-     import uvicorn
-     
      print(&quot;\n&quot; + &quot;=&quot;*80)
      print(&quot;ðŸš€ Starting AgentOS for &#39;Should I Move?&#39; Application&quot;)
```

**Chunk 2**
Lines added: 4, lines removed: 4

```diff
@@ -388,10 +386,10 @@
      print(&quot;\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)
      
-     # Run the FastAPI server
-     uvicorn.run(
-         app,
+     # Run the AgentOS server
+     agent_os.serve(
+         app=&quot;04-agno-agentos:app&quot;,
          host=&quot;0.0.0.0&quot;,
          port=7777,
-         log_level=&quot;info&quot;,
+         reload=True,
      )
  
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>




Now let me check if there are any linter errors in the file.</details></think>

---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** â€¢ Read lints for 1 file</summary>
      
Lint paths:

- `04-agno-agentos.py`

Lint results

Lint errors for `04-agno-agentos.py`


| Message | Range | Severity |
|-------|-------|----------|
| Import "datetime" is not accessed | 23:22-23:30 | DIAGNOSTIC_SEVERITY_HINT |
| Import "dotenv" could not be resolved | 24:6-24:12 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.agent" could not be resolved | 27:6-27:16 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.models.openai" could not be resolved | 28:6-28:24 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.team.team" could not be resolved | 29:6-29:20 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.tools.firecrawl" could not be resolved | 30:6-30:26 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.tools.local_file_system" could not be resolved | 31:6-31:34 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.db.postgres" could not be resolved | 32:6-32:22 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.knowledge.text" could not be resolved | 33:6-33:25 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.vectordb.pgvector" could not be resolved | 34:6-34:28 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "pydantic" could not be resolved | 35:6-35:14 | DIAGNOSTIC_SEVERITY_WARNING |
| Import "agno.os" could not be resolved | 352:6-352:13 | DIAGNOSTIC_SEVERITY_WARNING |


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
These are just import resolution warnings because the linter can't find the packages in the virtual environment. These are not real errors - they're just warnings that the packages aren't installed in the linter's path. The actual code should work fine once the packages are installed in the .venv.

Let me now run the file to see if it works.</details></think>

---

The linter errors are just warnings about unresolved imports (because packages aren't installed in the linter's environment). The code itself should work. Let me test it:

---

<tool-use data-tool-type="bash" data-tool-name="run_terminal_cmd">
<details><summary>Tool use: **command** â€¢ Run command: cd /c/CodeWork/should-i-move && source .venv/Scripts/activate && python 04-agno-agentos.py</summary>

```bash
cd /c/CodeWork/should-i-move && source .venv/Scripts/activate && python 04-agno-agentos.py
```
</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
The server started but I can't see the output yet. Let me wait a moment and then check if there are any errors. Actually, let me try a different approach - let me just try to import the modules to see if the imports work.</details></think>

---

Let me check if the script is running or if there are any errors:

---

Cancelled

---

_**User (2025-11-06 20:41Z)**_

how do I activate the virtual environment

---

_**Agent (model claude-4.5-sonnet-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is asking how to activate the virtual environment. They're on Windows (using Git Bash based on the shell output). Let me provide clear instructions for their specific setup.

From the project layout, I can see they have a `venv` directory (not `.venv`). They're using Git Bash on Windows.

For Git Bash on Windows, the activation command is:
- `source venv/Scripts/activate`

Or for Windows CMD/PowerShell:
- CMD: `venv\Scripts\activate.bat`
- PowerShell: `venv\Scripts\Activate.ps1`

Let me give them clear, concise instructions.</details></think>

---

## Activate Virtual Environment

Since you're using **Git Bash on Windows** and have a `venv` directory:

```bash
source venv/Scripts/activate
```

You'll see `(venv)` appear at the start of your prompt when activated.

### Alternative Shells:

**Windows Command Prompt (CMD):**
```cmd
venv\Scripts\activate.bat
```

**Windows PowerShell:**
```powershell
venv\Scripts\Activate.ps1
```

### After Activation

Then you can run:
```bash
python 04-agno-agentos.py
```

### Quick Test

Verify it's working:
```bash
# After activating
which python
# Should show: /c/CodeWork/should-i-move/venv/Scripts/python
```

### To Deactivate

When you're done:
```bash
deactivate
```

---

_**User (2025-11-06 20:41Z)**_

(.venv) 

ahmed@TheMountain MINGW64 /c/CodeWork/should-i-move (main)

$ python 04-agno-agentos.py 

Traceback (most recent call last):

  File "C:\CodeWork\should-i-move\04-agno-agentos.py", line 33, in <module>

    from agno.knowledge.text import TextKnowledgeBase

ModuleNotFoundError: No module named 'agno.knowledge.text'

(.venv) 

---

_**Agent (model claude-4.5-sonnet-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is getting another import error. It seems the `agno.knowledge.text` module doesn't exist in the current version of Agno. Let me search the official docs to find the correct way to handle knowledge bases in AgentOS.</details></think>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_docs-agno_SearchAgno">
<details>
          <summary>Tool use: **mcp_docs-agno_SearchAgno**</summary>
      
*Called tool*: docs-agno - SearchAgno: Search across the Agno knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Agno, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation pages.

*Parameters*:
  * query: knowledge base TextKnowledgeBase import

*Result*:
Title: Knowledge Base Architecture
Link: https://docs.agno.com/concepts/knowledge/core-concepts/knowledge-bases
Content: Knowledge bases in Agno are architecturally designed for AI agent retrieval, with specialized components that bridge the gap between raw data storage and intelligent information access.

Here's how the different pieces work together: Content Ingestion Raw content is processed through readers that understand different file formats (PDF, websites, databases, etc.) and extract meaningful text. Intelligent Chunking Large documents are broken down into smaller, meaningful pieces using chunking strategies that preserve context while enabling precise retrieval. Embedding Generation Each chunk is converted into a vector embedding that captures its semantic meaning using embedders powered by language models. Vector Storage Embeddings are stored in vector databases optimized for similarity search, often with support for hybrid search combining semantic and keyword matching. Intelligent Retrieval When agents need information, they generate search queries, find similar embeddings, and retrieve the most relevant content chunks.

Getting Started with Knowledge Bases
Ready to build your own knowledge base? The process is straightforward: from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.openai import OpenAIEmbedder

# Customized knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        table_name="company_knowledge",
        embedder=OpenAIEmbedder(model="text-embedding-3-large")
    )
)



*Result*:
Title: Agent with Knowledge Base
Link: https://docs.agno.com/examples/models/azure/ai_foundry/knowledge
Content: Code
"""Run `pip install ddgs sqlalchemy pgvector pypdf openai` to install dependencies."""
import asyncio
from agno.agent import Agent
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.azure import AzureAIFoundry
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
# Add content to the knowledge
asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
))

agent = Agent(
    model=AzureAIFoundry(id="Cohere-command-r-08-2024"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)

Code
"""Run `pip install ddgs sqlalchemy pgvector pypdf openai` to install dependencies."""
import asyncio
from agno.agent import Agent
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.azure import AzureAIFoundry
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
# Add content to the knowledge
asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
))

agent = Agent(
    model=AzureAIFoundry(id="Cohere-command-r-08-2024"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)

Usage
Set your API key Install libraries Run PgVector Run Agent python cookbook/models/azure/ai_foundry/knowledge.py



*Result*:
Title: Agent with Knowledge Base
Link: https://docs.agno.com/examples/models/azure/openai/knowledge
Content: Code
import asyncio
from agno.agent import Agent
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.azure import AzureOpenAI
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
# Add content to the knowledge
asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
))

agent = Agent(
    model=AzureOpenAI(id="gpt-5-mini"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)

Code
import asyncio
from agno.agent import Agent
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.azure import AzureOpenAI
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
# Add content to the knowledge
asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
))

agent = Agent(
    model=AzureOpenAI(id="gpt-5-mini"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)



*Result*:
Title: Deep Knowledge Agent
Link: https://docs.agno.com/examples/models/groq/deep_knowledge
Content: Code
"""ðŸ¤” DeepKnowledge - An AI Agent that iteratively searches a knowledge base to answer questions

This agent performs iterative searches through its knowledge base, breaking down complex
queries into sub-questions, and synthesizing comprehensive answers. It's designed to explore
topics deeply and thoroughly by following chains of reasoning.

In this example, the agent uses the Agno documentation as a knowledge base

Key Features:
- Iteratively searches a knowledge base
- Source attribution and citations
"""

from textwrap import dedent
from typing import List, Optional

import inquirer
import typer
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.groq import Groq
from agno.vectordb.lancedb import LanceDb, SearchType
from rich import print


def initialize_knowledge_base():
    """Initialize the knowledge base with your preferred documentation or knowledge source
    Here we use Agno docs as an example, but you can replace with any relevant URLs
    """
    agent_knowledge = Knowledge(
        vector_db=LanceDb(
            uri="tmp/lancedb",
            table_name="deep_knowledge_knowledge",
            search_type=SearchType.hybrid,
            embedder=OpenAIEmbedder(id="text-embedding-3-small"),
        ),
    )
    agent_knowledge.add_content(url="https://docs.agno.com/llms-full.txt")
    return agent_knowledge


def get_db():
    return SqliteDb(db_file="tmp/agents.db")


def create_agent(session_id: Optional[str] = None) -> Agent:
    """Create and return a configured DeepKnowledge agent."""
    agent_knowledge = initialize_knowledge_base()
    db = get_db()
    return Agent(
        name="DeepKnowledge",
        session_id=session_id,
        model=Groq(id="llama-3.3-70b-versatile"),
        description=dedent("""\
        You are DeepKnowledge, an advanced reasoning agent designed to provide thorough,
        well-researched answers to any query by searching your knowledge base.

        Your strengths include:
        - Breaking down complex topics into manageable components
        - Connecting information across multiple domains
        - Providing nuanced, well-researched answers
        - Maintaining intellectual honesty and citing sources
        - Explaining complex concepts in clear, accessible terms"""),
        instructions=dedent("""\
        Your mission is to leave no stone unturned in your pursuit of the correct answer.

        To achieve this, follow these steps:
        1. **Analyze the input and break it down into key components**.
        2. **Search terms**: You must identify at least 3-5 key search terms to search for.
        3. **Initial Search:** Searching your knowledge base for relevant information. You must make atleast 3 searches to get all relevant information.
        4. **Evaluation:** If the answer from the knowledge base is incomplete, ambiguous, or insufficient - Ask the user for clarification. Do not make informed guesses.
        5. **Iterative Process:**
            - Continue searching your knowledge base till you have a comprehensive answer.
            - Reevaluate the completeness of your answer after each search iteration.
            - Repeat the search process until you are confident that every aspect of the question is addressed.
        4. **Reasoning Documentation:** Clearly document your reasoning process:
            - Note when additional searches were triggered.
            - Indicate which pieces of information came from the knowledge base and where it was sourced from.
            - Explain how you reconciled any conflicting or ambiguous information.
        5. **Final Synthesis:** Only finalize and present your answer once you have verified it through multiple search passes.
            Include all pertinent details and provide proper references.
        6. **Continuous Improvement:** If new, relevant information emerges even after presenting your answer,
            be prepared to update or expand upon your response.

        **Communication Style:**
        - Use clear and concise language.
        - Organize your response with numbered steps, bullet points, or short paragraphs as needed.
        - Be transparent about your search process and cite your sources.
        - Ensure that your final answer is comprehensive and leaves no part of the query unaddressed.

        Remember: **Do not finalize your answer until every angle of the question has been explored.**"""),
        additional_context=dedent("""\
        You should only respond with the final answer and the reasoning process.
        No need to include irrelevant information.

        - User ID: {user_id}
        - Memory: You have access to your previous search results and reasoning process.
        """),
        knowledge=agent_knowledge,
        db=db,
        add_history_to_context=True,
        num_history_runs=3,
        read_chat_history=True,
        markdown=True,
    )


def get_example_topics() -> List[str]:
    """Return a list of example topics for the agent."""
    return [
        "What are AI agents and how do they work in Agno?",
        "What chunking strategies does Agno support for text processing?",
        "How can I implement custom tools in Agno?",
        "How does knowledge retrieval work in Agno?",
        "What types of embeddings does Agno support?",
    ]


def handle_session_selection() -> Optional[str]:
    """Handle session selection and return the selected session ID."""
    db = get_db()

    new = typer.confirm("Do you want to start a new session?", default=True)
    if new:
        return None

    existing_sessions = db.get_sessions()
    if not existing_sessions:
        print("No existing sessions found. Starting a new session.")
        return None

    print("\nExisting sessions:")
    for i, session in enumerate(existing_sessions, 1):
        print(f"{i}. {session.session_id}")  # type: ignore

    session_idx = typer.prompt(
        "Choose a session number to continue (or press Enter for most recent)",
        default=1,
    )

    try:
        return existing_sessions[int(session_idx) - 1].session_id  # type: ignore
    except (ValueError, IndexError):
        return existing_sessions[0].session_id  # type: ignore


def run_interactive_loop(agent: Agent):
    """Run the interactive question-answering loop."""
    example_topics = get_example_topics()

    while True:
        choices = [f"{i + 1}. {topic}" for i, topic in enumerate(example_topics)]
        choices.extend(["Enter custom question...", "Exit"])

        questions = [
            inquirer.List(
                "topic",
                message="Select a topic or ask a different question:",
                choices=choices,
            )
        ]
        answer = inquirer.prompt(questions)

        if answer and answer["topic"] == "Exit":
            break

        if answer and answer["topic"] == "Enter custom question...":
            questions = [inquirer.Text("custom", message="Enter your question:")]
            custom_answer = inquirer.prompt(questions)
            topic = custom_answer["custom"]  # type: ignore
        else:
            topic = example_topics[int(answer["topic"].split(".")[0]) - 1]  # type: ignore

        agent.print_response(topic, stream=True)


def deep_knowledge_agent():
    """Main function to run the DeepKnowledge agent."""

    session_id = handle_session_selection()
    agent = create_agent(session_id)

    print("\nðŸ¤” Welcome to DeepKnowledge - Your Advanced Research Assistant! ðŸ“š")
    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"[bold green]Started New Session: {session_id}[/bold green]\n")
        else:
            print("[bold green]Started New Session[/bold green]\n")
    else:
        print(f"[bold blue]Continuing Previous Session: {session_id}[/bold blue]\n")

    run_interactive_loop(agent)


if __name__ == "__main__":
    typer.run(deep_knowledge_agent)

Code
"""ðŸ¤” DeepKnowledge - An AI Agent that iteratively searches a knowledge base to answer questions

This agent performs iterative searches through its knowledge base, breaking down complex
queries into sub-questions, and synthesizing comprehensive answers. It's designed to explore
topics deeply and thoroughly by following chains of reasoning.

In this example, the agent uses the Agno documentation as a knowledge base

Key Features:
- Iteratively searches a knowledge base
- Source attribution and citations
"""

from textwrap import dedent
from typing import List, Optional

import inquirer
import typer
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.groq import Groq
from agno.vectordb.lancedb import LanceDb, SearchType
from rich import print


def initialize_knowledge_base():
    """Initialize the knowledge base with your preferred documentation or knowledge source
    Here we use Agno docs as an example, but you can replace with any relevant URLs
    """
    agent_knowledge = Knowledge(
        vector_db=LanceDb(
            uri="tmp/lancedb",
            table_name="deep_knowledge_knowledge",
            search_type=SearchType.hybrid,
            embedder=OpenAIEmbedder(id="text-embedding-3-small"),
        ),
    )
    agent_knowledge.add_content(url="https://docs.agno.com/llms-full.txt")
    return agent_knowledge


def get_db():
    return SqliteDb(db_file="tmp/agents.db")


def create_agent(session_id: Optional[str] = None) -> Agent:
    """Create and return a configured DeepKnowledge agent."""
    agent_knowledge = initialize_knowledge_base()
    db = get_db()
    return Agent(
        name="DeepKnowledge",
        session_id=session_id,
        model=Groq(id="llama-3.3-70b-versatile"),
        description=dedent("""\
        You are DeepKnowledge, an advanced reasoning agent designed to provide thorough,
        well-researched answers to any query by searching your knowledge base.

        Your strengths include:
        - Breaking down complex topics into manageable components
        - Connecting information across multiple domains
        - Providing nuanced, well-researched answers
        - Maintaining intellectual honesty and citing sources
        - Explaining complex concepts in clear, accessible terms"""),
        instructions=dedent("""\
        Your mission is to leave no stone unturned in your pursuit of the correct answer.

        To achieve this, follow these steps:
        1. **Analyze the input and break it down into key components**.
        2. **Search terms**: You must identify at least 3-5 key search terms to search for.
        3. **Initial Search:** Searching your knowledge base for relevant information. You must make atleast 3 searches to get all relevant information.
        4. **Evaluation:** If the answer from the knowledge base is incomplete, ambiguous, or insufficient - Ask the user for clarification. Do not make informed guesses.
        5. **Iterative Process:**
            - Continue searching your knowledge base till you have a comprehensive answer.
            - Reevaluate the completeness of your answer after each search iteration.
            - Repeat the search process until you are confident that every aspect of the question is addressed.
        4. **Reasoning Documentation:** Clearly document your reasoning process:
            - Note when additional searches were triggered.
            - Indicate which pieces of information came from the knowledge base and where it was sourced from.
            - Explain how you reconciled any conflicting or ambiguous information.
        5. **Final Synthesis:** Only finalize and present your answer once you have verified it through multiple search passes.
            Include all pertinent details and provide proper references.
        6. **Continuous Improvement:** If new, relevant information emerges even after presenting your answer,
            be prepared to update or expand upon your response.

        **Communication Style:**
        - Use clear and concise language.
        - Organize your response with numbered steps, bullet points, or short paragraphs as needed.
        - Be transparent about your search process and cite your sources.
        - Ensure that your final answer is comprehensive and leaves no part of the query unaddressed.

        Remember: **Do not finalize your answer until every angle of the question has been explored.**"""),
        additional_context=dedent("""\
        You should only respond with the final answer and the reasoning process.
        No need to include irrelevant information.

        - User ID: {user_id}
        - Memory: You have access to your previous search results and reasoning process.
        """),
        knowledge=agent_knowledge,
        db=db,
        add_history_to_context=True,
        num_history_runs=3,
        read_chat_history=True,
        markdown=True,
    )


def get_example_topics() -> List[str]:
    """Return a list of example topics for the agent."""
    return [
        "What are AI agents and how do they work in Agno?",
        "What chunking strategies does Agno support for text processing?",
        "How can I implement custom tools in Agno?",
        "How does knowledge retrieval work in Agno?",
        "What types of embeddings does Agno support?",
    ]


def handle_session_selection() -> Optional[str]:
    """Handle session selection and return the selected session ID."""
    db = get_db()

    new = typer.confirm("Do you want to start a new session?", default=True)
    if new:
        return None

    existing_sessions = db.get_sessions()
    if not existing_sessions:
        print("No existing sessions found. Starting a new session.")
        return None

    print("\nExisting sessions:")
    for i, session in enumerate(existing_sessions, 1):
        print(f"{i}. {session.session_id}")  # type: ignore

    session_idx = typer.prompt(
        "Choose a session number to continue (or press Enter for most recent)",
        default=1,
    )

    try:
        return existing_sessions[int(session_idx) - 1].session_id  # type: ignore
    except (ValueError, IndexError):
        return existing_sessions[0].session_id  # type: ignore


def run_interactive_loop(agent: Agent):
    """Run the interactive question-answering loop."""
    example_topics = get_example_topics()

    while True:
        choices = [f"{i + 1}. {topic}" for i, topic in enumerate(example_topics)]
        choices.extend(["Enter custom question...", "Exit"])

        questions = [
            inquirer.List(
                "topic",
                message="Select a topic or ask a different question:",
                choices=choices,
            )
        ]
        answer = inquirer.prompt(questions)

        if answer and answer["topic"] == "Exit":
            break

        if answer and answer["topic"] == "Enter custom question...":
            questions = [inquirer.Text("custom", message="Enter your question:")]
            custom_answer = inquirer.prompt(questions)
            topic = custom_answer["custom"]  # type: ignore
        else:
            topic = example_topics[int(answer["topic"].split(".")[0]) - 1]  # type: ignore

        agent.print_response(topic, stream=True)


def deep_knowledge_agent():
    """Main function to run the DeepKnowledge agent."""

    session_id = handle_session_selection()
    agent = create_agent(session_id)

    print("\nðŸ¤” Welcome to DeepKnowledge - Your Advanced Research Assistant! ðŸ“š")
    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"[bold green]Started New Session: {session_id}[/bold green]\n")
        else:
            print("[bold green]Started New Session[/bold green]\n")
    else:
        print(f"[bold blue]Continuing Previous Session: {session_id}[/bold blue]\n")

    run_interactive_loop(agent)


if __name__ == "__main__":
    typer.run(deep_knowledge_agent)

Usage
Set your API key Install libraries Run Agent python cookbook/models/groq/deep_knowledge.py



*Result*:
Title: Couchbase Agent Knowledge
Link: https://docs.agno.com/concepts/vectordb/couchbase
Content: Local Setup (Docker)
Run Couchbase locally using Docker: docker run -d --name couchbase-server \
  -p 8091-8096:8091-8096 \
  -p 11210:11210 \
  -e COUCHBASE_ADMINISTRATOR_USERNAME=Administrator \
  -e COUCHBASE_ADMINISTRATOR_PASSWORD=password \
  couchbase:latest

Example
Async Support âš¡ Couchbase also supports asynchronous operations, enabling concurrency and leading to better performance. import asyncio
import os
import time
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.couchbase import CouchbaseSearch
from couchbase.options import ClusterOptions, KnownConfigProfiles
from couchbase.auth import PasswordAuthenticator
from couchbase.management.search import SearchIndex

# Couchbase connection settings
username = os.getenv("COUCHBASE_USER")
password = os.getenv("COUCHBASE_PASSWORD")
connection_string = os.getenv("COUCHBASE_CONNECTION_STRING")

# Create cluster options with authentication
auth = PasswordAuthenticator(username, password)
cluster_options = ClusterOptions(auth)
cluster_options.apply_profile(KnownConfigProfiles.WanDevelopment)

knowledge_base = Knowledge(
    vector_db=CouchbaseSearch(
        bucket_name="recipe_bucket",
        scope_name="recipe_scope",
        collection_name="recipes",
        couchbase_connection_string=connection_string,
        cluster_options=cluster_options,
        search_index="vector_search_fts_index",
        embedder=OpenAIEmbedder(
            id="text-embedding-3-large", 
            dimensions=3072, 
            api_key=os.getenv("OPENAI_API_KEY")
        ),
        wait_until_index_ready=60,
        overwrite=True
    ),
)

# Create and use the agent
agent = Agent(knowledge=knowledge_base)

async def run_agent():
    await knowledge_base.add_content_async(
      url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    )
    time.sleep(5)  # Wait for the vector index to sync with KV
    await agent.aprint_response("How to make Thai curry?", markdown=True)

if __name__ == "__main__":
    asyncio.run(run_agent())

Example
import os
import time
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.couchbase import CouchbaseSearch
from couchbase.options import ClusterOptions, KnownConfigProfiles
from couchbase.auth import PasswordAuthenticator
from couchbase.management.search import SearchIndex

# Couchbase connection settings
username = os.getenv("COUCHBASE_USER")
password = os.getenv("COUCHBASE_PASSWORD")
connection_string = os.getenv("COUCHBASE_CONNECTION_STRING")

# Create cluster options with authentication
auth = PasswordAuthenticator(username, password)
cluster_options = ClusterOptions(auth)
cluster_options.apply_profile(KnownConfigProfiles.WanDevelopment)


knowledge_base = Knowledge(
    vector_db=CouchbaseSearch(
        bucket_name="recipe_bucket",
        scope_name="recipe_scope",
        collection_name="recipes",
        couchbase_connection_string=connection_string,
        cluster_options=cluster_options,
        search_index="vector_search_fts_index",
        embedder=OpenAIEmbedder(
            id="text-embedding-3-large", 
            dimensions=3072, 
            api_key=os.getenv("OPENAI_API_KEY")
        ),
        wait_until_index_ready=60,
        overwrite=True
    ),
)

# Load the knowledge base
knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

# Wait for the vector index to sync with KV
time.sleep(20)

# Create and use the agent
agent = Agent(knowledge=knowledge_base)
agent.print_response("How to make Thai curry?", markdown=True)



*Result*:
Title: Agent with Knowledge Base
Link: https://docs.agno.com/examples/models/cerebras/knowledge
Content: Code
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.cerebras import Cerebras
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=Cerebras(id="llama-4-scout-17b-16e-instruct"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)

Code
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.cerebras import Cerebras
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=Cerebras(id="llama-4-scout-17b-16e-instruct"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)

Usage
Set your API key Install libraries Start your Postgres server Ensure your Postgres server is running and accessible at the connection string used in db_url. Run Agent (first time) The first run will load and index the PDF. This may take a while. Subsequent Runs After the first run, comment out or remove knowledge_base.load(recreate=True) to avoid reloading the PDF each time.



*Result*:
Title: Team with Knowledge Base
Link: https://docs.agno.com/examples/concepts/teams/knowledge/team_with_knowledge
Content: This example demonstrates how to create a team with knowledge base integration. The team has access to a knowledge base with Agno documentation and can combine this knowledge with web search capabilities.

Team with Knowledge Base
This example demonstrates how to create a team with knowledge base integration. The team has access to a knowledge base with Agno documentation and can combine this knowledge with web search capabilities.

Code
"""
This example demonstrates how to create a team with knowledge base integration.

The team has access to a knowledge base with Agno documentation and can combine
this knowledge with web search capabilities.
"""

from pathlib import Path

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.lancedb import LanceDb, SearchType

# Setup paths for knowledge storage
cwd = Path(__file__).parent
tmp_dir = cwd.joinpath("tmp")
tmp_dir.mkdir(parents=True, exist_ok=True)

# Initialize knowledge base with vector database
agno_docs_knowledge = Knowledge(
    vector_db=LanceDb(
        uri=str(tmp_dir.joinpath("lancedb")),
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Add content to knowledge base
agno_docs_knowledge.add_content(url="https://docs.agno.com/llms-full.txt")

# Create web search agent for supplementary information
web_agent = Agent(
    name="Web Search Agent",
    role="Handle web search requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=["Always include sources"],
)

# Create team with knowledge base integration
team_with_knowledge = Team(
    name="Team with Knowledge",
    members=[web_agent],
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=agno_docs_knowledge,
    show_members_responses=True,
    markdown=True,
)

if __name__ == "__main__":
    team_with_knowledge.print_response("Tell me about the Agno framework", stream=True)



*Result*:
Title: Knowledge Base
Link: https://docs.agno.com/concepts/knowledge/core-concepts/terminology
Content: A structured repository of information that agents can search and retrieve from at runtime. Contains processed content optimized for AI understanding and retrieval.

Example: Dynamic Few-Shot Learning in Action
Scenario:  Building a Text-to-SQL Agent Instead of cramming all table schemas, column names, and example queries into the system prompt, you store this information in a knowledge base. When a user asks for data, the agent: Analyzes the request Searches for relevant schema information and example queries Uses the retrieved context to generate the best possible SQL query This is "dynamic" because the agent gets exactly the information it needs for each specific query, and "few-shot" because it learns from examples retrieved at runtime.

Dynamic Few-Shot Learning
The pattern where agents retrieve specific examples or context at runtime to improve their performance on tasks, rather than having all information provided upfront. Scenario: Building a Text-to-SQL Agent Instead of cramming all table schemas, column names, and example queries into the system prompt, you store this information in a knowledge base. When a user asks for data, the agent: Analyzes the request Searches for relevant schema information and example queries Uses the retrieved context to generate the best possible SQL query This is "dynamic" because the agent gets exactly the information it needs for each specific query, and "few-shot" because it learns from examples retrieved at runtime.



*Result*:
Title: Knowledge
Link: https://docs.agno.com/how-to/v2-changelog
Content: Knowledge has been completely reworked. See full details in the Knowledge section. You now define a single Knowledge instance for all types of content. Files (PDF, CSV, etc.), URLs, and other. The agent can still use your knowledge base to search for information at runtime. All existing RAG implementations are still supported. Added full async support for embedding models and vector DBs. This has a significant impact on performance and is a major speed improvement when adding content to the knowledge base using knowledge.add_content_async(...). AgentKnowledge and all other knowledge base classes have been removed. Import locations for embedder , document , chunking , reranker and reader have been moved to agno.knowledge . See examples for more details.

Updates to 
knowledge  is now an instance of  Knowledge  instead of  AgentKnowledge . retriever  ->  knowledge_retriever  -> For a custom retriever. add_references  ->  add_knowledge_to_context  -> To enable traditional RAG. Added  update_knowledge  tool to update the knowledge base. Works the same as for  Agent .

Updates to 
knowledge  is now an instance of  Knowledge  instead of  AgentKnowledge . retriever  ->  knowledge_retriever  -> For a custom retriever. add_references  ->  add_knowledge_to_context  -> To enable traditional RAG.



*Result*:
Title: Step 1: Set Up Your Knowledge Base
Link: https://docs.agno.com/concepts/knowledge/getting-started
Content: First, let's create a knowledge base with a vector database to store your information: from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.models.openai import OpenAIChat

# Create a knowledge base with PgVector
knowledge = Knowledge(
    vector_db=PgVector(
        table_name="knowledge_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

# Create an agent with knowledge
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    knowledge=knowledge,
    # Enable automatic knowledge search
    search_knowledge=True,
    instructions=[
        "Always search your knowledge base before answering questions",
        "Include source references in your responses when possible"
    ]
)

First, let's create a knowledge base with a vector database to store your information: For a quick start without setting up PostgreSQL, use LanceDB which stores data locally: from agno.vectordb.lancedb import LanceDb

# Local vector storage - no database setup required
knowledge = Knowledge(
    vector_db=LanceDb(
        table_name="knowledge_documents",
        uri="tmp/lancedb"  # Local directory for storage
    ),
)

First, let's create a knowledge base with a vector database to store your information: For a quick start without setting up PostgreSQL, use LanceDB which stores data locally:


</details>
</tool-use>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_docs-agno_SearchAgno">
<details>
          <summary>Tool use: **mcp_docs-agno_SearchAgno**</summary>
      
*Called tool*: docs-agno - SearchAgno: Search across the Agno knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Agno, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation pages.

*Parameters*:
  * query: AgentOS knowledge upload documents

*Result*:
Title: AgentOS API
Link: https://docs.agno.com/agent-os/api
Content: AgentOS is a RESTful API that provides access to your agentic system. It allows you to: Run Agents / Teams / Workflows : Create new runs for your agents, teams and workflows, either with a new session or a existing one. Manage Sessions : Retrieve, update and delete sessions. Manage Memories : Retrieve, update and delete memories. Manage Knowledge : Manage the content of your knowledge base. Manage Evals : Retrieve, create, delete and update evals. This is the same API that powers the AgentOS Control Plane. However, the same endpoints can be used to power your own application! See the full API reference for more details.

Learn how to use the AgentOS API to interact with your agentic system

Passing agent parameters
Agent, Team and Workflow run() and arun() endpoints all support additional parameters. See the Agent arun schema , Team arun schema , Workflow arun schema for more details. To pass these parameters to your agent, team or workflow, via the , you can simply specify them as form-based parameters. Below is an example where dependencies are passed to the agent: from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.os import AgentOS

# Setup the database
db = PostgresDb(id="basic-db", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

# Setup basic agents, teams and workflows
story_writer = Agent(
    id="story-writer-agent",
    name="Story Writer Agent",
    db=db,
    markdown=True,
    instructions="You are a story writer. You are asked to write a story about a robot. Always name the robot {robot_name}",
)

# Setup our AgentOS app
agent_os = AgentOS(
    description="Example AgentOS to show how to pass dependencies to an agent",
    agents=[story_writer],
)
app = agent_os.get_app()


if __name__ == "__main__":
    agent_os.serve(app="dependencies_to_agent:app", reload=True)



*Result*:
Title: Team with Agentic Knowledge Filters
Link: https://docs.agno.com/examples/concepts/teams/knowledge/team_with_agentic_knowledge_filters
Content: This example demonstrates how to use agentic knowledge filters with teams. Unlike predefined filters, agentic knowledge filters allow the AI to dynamically determine which documents to search based on the query context, providing more intelligent and context-aware document retrieval.

Team with Agentic Knowledge Filters
This example demonstrates how to use agentic knowledge filters with teams. Unlike predefined filters, agentic knowledge filters allow the AI to dynamically determine which documents to search based on the query context, providing more intelligent and context-aware document retrieval.



*Result*:
Title: Managing Knowledge via AgentOS control plane
Link: https://docs.agno.com/agent-os/customize/os/manage_knowledge
Content: Once your Knowledge bases are attached to AgentOS, you can: View Content : Browse and search through your Knowledge base contents Add Content : Upload new documents, add URLs, or input text directly Edit Content : Modify metadata on existing Knowledge entries Delete Content : Remove outdated or incorrect information

Manage Knowledge
You can manage Agno Knowledge instances through the AgentOS control plane.
This allows you to add, edit and remove content from your Knowledge bases
independently of any specific Agent or Team. You can specify multiple Knowledge bases and reuse the same Knowledge instance
across different Agents or Teams as needed.

Knowledge base not appearing in AgentOS interface
Ensure your knowledge base is properly added to the  knowledge  parameter when creating your AgentOS instance.
Also make sure to attach a  contents_db  to your Knowledge instance.



*Result*:
Title: What is AgentOS?
Link: https://docs.agno.com/agent-os/introduction
Content: The production runtime and control plane for your agentic systems

Overview
AgentOS is Agno's production-ready runtime that runs entirely within your own infrastructure, ensuring complete data privacy and control of your agentic system.
Agno also provides a beautiful web interface for managing, monitoring, and interacting with your AgentOS, with no data ever being persisted outside of your environment. Behind the scenes, AgentOS is a FastAPI app that you can run locally or in your cloud. It is designed to be easy to deploy and scale.



*Result*:
Title: AgentOS Features Enabled by ContentsDB
Link: https://docs.agno.com/concepts/knowledge/content_db
Content: With ContentsDB, the AgentOS Knowledge page provides: Content Browser : View all uploaded content with metadata Upload Interface : Add new content through the web UI Status Monitoring : Real-time processing status updates Metadata Editor : Update content metadata through forms Content Management : Delete or modify content entries Search and Filtering : Find content by metadata attributes Bulk Operations : Manage multiple content items at once Check out the AgentOS Knowledge page for more in-depth information.

Required Setup for AgentOS
When using AgentOS, ContentsDB is mandatory for the Knowledge management interface: from agno.os import AgentOS
from agno.db.postgres import PostgresDb
from agno.agent import Agent

# ContentsDB is required for AgentOS Knowledge page
contents_db = PostgresDb(
    db_url="postgresql+psycopg://user:pass@localhost:5432/db"
)

vector_db = PgVector(table_name="vectors", db_url="http://my-postgress:5432")


knowledge = Knowledge(
    vector_db=vector_db,
    contents_db=contents_db  # Must be provided for AgentOS
)

knowledge_agent = Agent(
    name="Knowledge Agent",
    knowledge=knowledge
)

# Create AgentOS app
app = AgentOS(
    description="Example app for basic agent with knowledge capabilities",
    id="knowledge-demo",
    agents=[knowledge_agent],
)

Required for AgentOS
If you're using AgentOS, ContentsDB is mandatory for the Knowledge page functionality. The AgentOS web interface relies on ContentsDB to display and manage your knowledge content.



*Result*:
Title: AgentOS Parameters
Link: https://docs.agno.com/agent-os/customize/os/attributes
Content: You can configure the behaviour of your AgentOS by passing the following parameters to the AgentOS class: agents : List of agents to include in the AgentOS teams : List of teams to include in the AgentOS workflows : List of workflows to include in the AgentOS knowledge : List of knowledge instances to include in the AgentOS interfaces : List of interfaces to include in the AgentOS See the Interfaces section for more details. config : Configuration file path or AgentOSConfig instance See the Configuration page for more details. base_app : Optional custom FastAPI app to use instead of creating a new one See the Custom FastAPI App page for more details. lifespan : Optional lifespan context manager for the FastAPI app See the Lifespan page for more details. enable_mcp_server : Turn your AgentOS into an MCP server See the MCP enabled AgentOS page for more details. on_route_conflict : Optionally preserve your custom routes over AgentOS routes (set to "preserve_base_app" ). Defaults to "preserve_agentos" , preserving the AgentOS routes See the Overriding Routes page for more details. See the AgentOS class reference for more details.

Learn about the attributes of the AgentOS class



*Result*:
Title: Knowledge Management
Link: https://docs.agno.com/agent-os/features/knowledge-management
Content: Upload, organize, and manage knowledge for your agents in AgentOS

Overview
Upload files, add web pages, or paste text to build a searchable knowledge base for your agents. AgentOS indexes content and shows processing status so you can track whatâ€™s ready to use. Prerequisites : Your AgentOS must be connected and active. If
you see â€œDisconnectedâ€ or â€œInactive,â€ review your connection settings.

Useful Links
Agent Knowledge Learn how to add knowledge to agents and use RAG Team Knowledge Understand knowledge sharing in team environments



*Result*:
Title: AgentOS + MCPTools
Link: https://docs.agno.com/agent-os/mcp/tools
Content: Model Context Protocol (MCP) gives Agents the ability to interact with external systems through a standardized interface. You can give your agents access to tools from MCP servers using MCPTools. When using MCPTools within AgentOS, the lifecycle is automatically managed. No need to manually connect or disconnect the MCPTools instance. This does not automatically refresh connections that are interrupted or restarted, you can use refresh_connection to do so. If you are using MCPTools within AgentOS, you should not use reload=True when serving your AgentOS.
This can break the MCP connection during the FastAPI lifecycle. See here for a full example.

Model Context Protocol (MCP) gives Agents the ability to interact with external systems through a standardized interface. You can give your agents access to tools from MCP servers using MCPTools. When using MCPTools within AgentOS, the lifecycle is automatically managed. No need to manually connect or disconnect the MCPTools instance. from agno.agent import Agent
from agno.os import AgentOS
from agno.tools.mcp import MCPTools

# Create MCPTools instance
mcp_tools = MCPTools(
    transport="streamable-http", 
    url="https://docs.agno.com/mcp"
)

# Create MCP-enabled agent
agent = Agent(
    id="agno-agent",
    name="Agno Agent",
    tools=[mcp_tools],
)

# AgentOS manages MCP lifespan
agent_os = AgentOS(
    description="AgentOS with MCP Tools",
    agents=[agent],
)

app = agent_os.get_app()

if __name__ == "__main__":
    # Don't use reload=True with MCP tools to avoid lifespan issues
    agent_os.serve(app="mcp_tools_example:app")

Learn how to use MCPTools in your AgentOS



*Result*:
Title: Agent with Knowledge
Link: https://docs.agno.com/examples/models/groq/knowledge
Content: Code
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.groq import Groq
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)

Code
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.groq import Groq
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)

Usage
Set your API key Install libraries Run PgVector Run Agent python cookbook/models/groq/knowledge.py



*Result*:
Title: Agent With Knowledge
Link: https://docs.agno.com/examples/models/meta/knowledge
Content: Code
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.meta import Llama
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"), knowledge=knowledge
)
agent.print_response("How to make Thai curry?", markdown=True)

Code
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.meta import Llama
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"), knowledge=knowledge
)
agent.print_response("How to make Thai curry?", markdown=True)


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Perfect! I found the correct import. It's `from agno.knowledge.knowledge import Knowledge`, not `from agno.knowledge.text import TextKnowledgeBase`. Let me update the code.</details></think>

---

Found it! The correct import is `from agno.knowledge.knowledge import Knowledge`, not `TextKnowledgeBase`. Let me fix the code:

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -31,5 +31,5 @@
  from agno.tools.local_file_system import LocalFileSystemTools
  from agno.db.postgres import PostgresDb
- from agno.knowledge.text import TextKnowledgeBase
+ from agno.knowledge.knowledge import Knowledge
  from agno.vectordb.pgvector import PgVector
  from pydantic import BaseModel, Field
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to update the knowledge base instantiation from TextKnowledgeBase to Knowledge.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 2, lines removed: 3

```diff
@@ -67,9 +67,8 @@
  
  # Create a knowledge base with city relocation information
- relocation_knowledge = TextKnowledgeBase(
-     path=&quot;data&quot;,  # Load from data directory
+ relocation_knowledge = Knowledge(
      vector_db=vector_db,
-     reader=None,  # Will auto-detect file types
  )
+ # Note: Content can be added via AgentOS UI or using knowledge.add_content(path=&quot;data&quot;)
  
  # ============================================================================
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Good! Now let me test if the code runs. Let me also check if there are any other issues I need to fix based on the official documentation. I should also check the embedder parameter - it looks like it might need to be a specific embedder class, not just OpenAIChat.</details></think>

---

Let me check if the embedder setup is correct:

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_docs-agno_SearchAgno">
<details>
          <summary>Tool use: **mcp_docs-agno_SearchAgno**</summary>
      
*Called tool*: docs-agno - SearchAgno: Search across the Agno knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Agno, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation pages.

*Parameters*:
  * query: PgVector embedder OpenAIEmbedder example

*Result*:
Title: OpenAI Embedder
Link: https://docs.agno.com/examples/concepts/knowledge/embedders/openai-embedder
Content: Code
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = OpenAIEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="openai_embeddings",
        embedder=OpenAIEmbedder(),
    ),
    max_results=2,
)

Code
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = OpenAIEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="openai_embeddings",
        embedder=OpenAIEmbedder(),
    ),
    max_results=2,
)

Usage
Set your API key Install libraries Run PgVector Run Agent python cookbook/knowledge/embedders/openai_embedder.py



*Result*:
Title: Azure OpenAI Embedder
Link: https://docs.agno.com/examples/concepts/knowledge/embedders/azure-embedder
Content: Code
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = AzureOpenAIEmbedder(id="text-embedding-3-small").get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="azure_openai_embeddings",
        embedder=AzureOpenAIEmbedder(),
    ),
    max_results=2,
)

Code
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = AzureOpenAIEmbedder(id="text-embedding-3-small").get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="azure_openai_embeddings",
        embedder=AzureOpenAIEmbedder(),
    ),
    max_results=2,
)

Usage
Set your API key export AZURE_EMBEDDER_OPENAI_API_KEY=xxx
export AZURE_EMBEDDER_OPENAI_ENDPOINT=xxx
export AZURE_EMBEDDER_DEPLOYMENT=xxx



*Result*:
Title: OpenAI Embedder
Link: https://docs.agno.com/concepts/knowledge/embedder/openai
Content: OpenAI Embedder
Agno uses the OpenAIEmbedder as the default embeder for the vector database. The OpenAIEmbedder class is used to embed text data into vectors using the OpenAI API. Get your key from here.

Agno uses the OpenAIEmbedder as the default embeder for the vector database. The OpenAIEmbedder class is used to embed text data into vectors using the OpenAI API. Get your key from here.

Usage
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.openai import OpenAIEmbedder

# Embed sentence in database
embeddings = OpenAIEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="openai_embeddings",
        embedder=OpenAIEmbedder(),
    ),
    max_results=2,
)



*Result*:
Title: Traditional RAG with PgVector
Link: https://docs.agno.com/examples/concepts/agent/rag/traditional_rag_pgvector
Content: This example demonstrates traditional RAG implementation using PgVector database with OpenAI embeddings, where knowledge context is automatically added to prompts without search functionality.

Traditional RAG with PgVector
This example demonstrates traditional RAG implementation using PgVector database with OpenAI embeddings, where knowledge context is automatically added to prompts without search functionality.

Code
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    # Enable RAG by adding context from the `knowledge` to the user prompt.
    add_knowledge_to_context=True,
    # Set as False because Agents default to `search_knowledge=True`
    search_knowledge=False,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)



*Result*:
Title: Traditional RAG with PgVector
Link: https://docs.agno.com/examples/concepts/knowledge/rag/traditional-rag-pgvector
Content: Code
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    # Enable RAG by adding context from the `knowledge` to the user prompt.
    add_knowledge_to_context=True,
    # Set as False because Agents default to `search_knowledge=True`
    search_knowledge=False,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)

Code
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    # Enable RAG by adding context from the `knowledge` to the user prompt.
    add_knowledge_to_context=True,
    # Set as False because Agents default to `search_knowledge=True`
    search_knowledge=False,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)

Usage
Set your API key Install libraries pip install -U openai sqlalchemy psycopg pgvector pypdf agno



*Result*:
Title: Agentic RAG with PgVector
Link: https://docs.agno.com/examples/concepts/knowledge/rag/agentic-rag-pgvector
Content: Code
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)

Code
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)

Usage
Set your API key Install libraries pip install -U openai sqlalchemy psycopg pgvector agno



*Result*:
Title: VoyageAI Embedder
Link: https://docs.agno.com/examples/concepts/knowledge/embedders/voyageai-embedder
Content: Code
from agno.knowledge.embedder.voyageai import VoyageAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = VoyageAIEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="voyageai_embeddings",
        embedder=VoyageAIEmbedder(),
    ),
    max_results=2,
)

Code
from agno.knowledge.embedder.voyageai import VoyageAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = VoyageAIEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="voyageai_embeddings",
        embedder=VoyageAIEmbedder(),
    ),
    max_results=2,
)

Usage
Install libraries Run PgVector Run Agent python cookbook/knowledge/embedders/voyageai_embedder.py



*Result*:
Title: Azure OpenAI Embedder
Link: https://docs.agno.com/concepts/knowledge/embedder/azure_openai
Content: The AzureOpenAIEmbedder class is used to embed text data into vectors using the Azure OpenAI API. Get your key from here.

Azure OpenAI Embedder
The AzureOpenAIEmbedder class is used to embed text data into vectors using the Azure OpenAI API. Get your key from here.

Usage
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder

# Embed sentence in database
embeddings = AzureOpenAIEmbedder(id="text-embedding-3-small").get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="azure_openai_embeddings",
        embedder=AzureOpenAIEmbedder(id="text-embedding-3-small"),
    ),
    max_results=2,
)



*Result*:
Title: Qdrant FastEmbed Embedder
Link: https://docs.agno.com/examples/concepts/knowledge/embedders/qdrant-fastembed
Content: Code
from agno.knowledge.embedder.fastembed import FastEmbedEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = FastEmbedEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="qdrant_embeddings",
        embedder=FastEmbedEmbedder(),
    ),
    max_results=2,
)

Code
from agno.knowledge.embedder.fastembed import FastEmbedEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = FastEmbedEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="qdrant_embeddings",
        embedder=FastEmbedEmbedder(),
    ),
    max_results=2,
)

Usage
Install libraries Run PgVector Run Agent python cookbook/knowledge/embedders/qdrant_fastembed.py



*Result*:
Title: OpenAI
Link: https://docs.agno.com/reference/knowledge/embedder/openai
Content: OpenAI Embedder is a class that allows you to embed documents using OpenAI's embedding models, including the latest text-embedding-3 series.

OpenAI
OpenAI Embedder is a class that allows you to embed documents using OpenAI's embedding models, including the latest text-embedding-3 series.


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Perfect! I need to use `OpenAIEmbedder` from `agno.knowledge.embedder.openai`, not `OpenAIChat`. Let me fix this.</details></think>

---

Perfect! I need to use the correct embedder class. Let me fix it:

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: undefined

```diff
@@ -32,4 +32,5 @@
  from agno.db.postgres import PostgresDb
  from agno.knowledge.knowledge import Knowledge
+ from agno.knowledge.embedder.openai import OpenAIEmbedder
  from agno.vectordb.pgvector import PgVector
  from pydantic import BaseModel, Field
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to update the embedder parameter in the vector_db configuration.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -60,5 +60,5 @@
      table_name=&quot;agent_knowledge&quot;,
      db_url=DB_URL,
-     embedder=OpenAIChat(model=&quot;text-embedding-3-small&quot;),
+     embedder=OpenAIEmbedder(id=&quot;text-embedding-3-small&quot;),
  )
  
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Great! Now the code should be updated with all the correct imports and API according to the official Agno documentation. Let me make a summary document showing what was changed.</details></think>

---

Perfect! Now let's test it:

---

<tool-use data-tool-type="bash" data-tool-name="run_terminal_cmd">
<details><summary>Tool use: **command** â€¢ Run command: cd /c/CodeWork/should-i-move && source .venv/Scripts/activate && python -c "from agno.knowledge.knowledge import Knowledge; from agno.knowledge.embedder.openai import OpenAIEmbedder; print('âœ… All imports successful')"</summary>

```bash
cd /c/CodeWork/should-i-move && source .venv/Scripts/activate && python -c "from agno.knowledge.knowledge import Knowledge; from agno.knowledge.embedder.openai import OpenAIEmbedder; print('âœ… All imports successful')"
```

```
i import OpenAIEmbedder; print(&#39;âœ… All imports successful&#39;)&quot;                    
âœ… All imports successful
```
</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Great! The imports are working. Now let me run the full script to see if it starts up correctly.</details></think>

---

Excellent! The imports work. Now try running the full script:

```bash
python 04-agno-agentos.py
```

## Summary of Fixes

**Updated to Modern Agno API (based on official docs):**

1. **Database imports** - Changed from outdated API:
   - âŒ `agno.storage.agent.postgres.PgAgentStorage`
   - âŒ `agno.memory.db.postgres.PgMemoryDb`
   - âœ… `agno.db.postgres.PostgresDb` (handles both sessions and memory)

2. **Knowledge imports** - Fixed to current API:
   - âŒ `agno.knowledge.text.TextKnowledgeBase`
   - âœ… `agno.knowledge.knowledge.Knowledge`

3. **Embedder imports** - Fixed to proper embedder class:
   - âŒ `OpenAIChat(model="text-embedding-3-small")`
   - âœ… `OpenAIEmbedder(id="text-embedding-3-small")`

4. **AgentOS creation** - Updated to modern API:
   - âŒ `create_agentos_app()`
   - âœ… `AgentOS().get_app()`

5. **Server startup** - Updated to AgentOS method:
   - âŒ `uvicorn.run(app, ...)`
   - âœ… `agent_os.serve(app="...", ...)`

6. **Agent/Team parameters** - Simplified:
   - âŒ `storage=agent_storage, memory=memory_db`
   - âœ… `db=db` (single parameter handles both)

**Your virtual environment is `.venv` and it's correctly activated!** âœ…

---

_**User (2025-11-06 20:41Z)**_

ahmed@TheMountain MINGW64 /c/CodeWork/should-i-move (main)

$ python 04-agno-agentos.py 

Traceback (most recent call last):

  File "C:\CodeWork\should-i-move\04-agno-agentos.py", line 53, in <module>

    db = PostgresDb(

        table_name="agent_sessions",

        db_url=DB_URL,

    )

TypeError: PostgresDb.__init__() got an unexpected keyword argument 'table_name'

(.venv) 

---

_**Agent (model claude-4.5-sonnet-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is getting an error that `PostgresDb.__init__()` doesn't accept `table_name` as a keyword argument. Let me check the official docs for the correct PostgresDb parameters.</details></think>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_docs-agno_SearchAgno">
<details>
          <summary>Tool use: **mcp_docs-agno_SearchAgno**</summary>
      
*Called tool*: docs-agno - SearchAgno: Search across the Agno knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Agno, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation pages.

*Parameters*:
  * query: PostgresDb init parameters db_url session_table

*Result*:
Title: PostgresDb
Link: https://docs.agno.com/reference/storage/postgres
Content: PostgresDb is a class that implements the Db interface using PostgreSQL as the backend storage system. It provides robust, relational storage for agent sessions with support for JSONB data types, schema versioning, and efficient querying.

PostgresDb
PostgresDb is a class that implements the Db interface using PostgreSQL as the backend storage system. It provides robust, relational storage for agent sessions with support for JSONB data types, schema versioning, and efficient querying.



*Result*:
Title: Where are sessions stored?
Link: https://docs.agno.com/concepts/db/overview
Content: By default, sessions are stored in the agno_sessions table of the database. If the table or collection doesn't exist, it is created automatically when first storing a session. You can specify where the sessions are stored exactly using the session_table parameter: from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup your database
db = PostgresDb(
    db_url="postgresql://user:password@localhost:5432/my_database",
    session_table="my_session_table", # Specify the table to store sessions
)

# Setup your Agent with the database
agent = Agent(db=db)

# Run the Agent. This will store a session in our "my_session_table"
agent.print_response("What is the capital of France?")

By default, sessions are stored in the agno_sessions table of the database. If the table or collection doesn't exist, it is created automatically when first storing a session. You can specify where the sessions are stored exactly using the session_table parameter:

Retrieving sessions
You can manually retrieve stored sessions using the get_session method. This also works for Teams and Workflows: from agno.agent import Agent
from agno.db.sqlite import SQLiteDb

# Setup your database
db = SQLiteDb(db_file="agno.db")

# Setup your Agent with the database
agent = Agent(db=db)

# Run the Agent, effectively creating and persisting a session
agent.print_response("What is the capital of France?", session_id="123")

# Retrieve our freshly created session
session_history = agent.get_session(session_id="123")



*Result*:
Title: Memory with PostgreSQL
Link: https://docs.agno.com/examples/concepts/memory/db/mem-postgres-memory
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup Postgres
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    db=db,
    enable_user_memories=True,
)

agent.print_response("My name is John Doe and I like to play basketball on the weekends.")
agent.print_response("What's do I do in weekends?")

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup Postgres
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    db=db,
    enable_user_memories=True,
)

agent.print_response("My name is John Doe and I like to play basketball on the weekends.")
agent.print_response("What's do I do in weekends?")

Usage
Set environment variables Install libraries Run Example python cookbook/memory/db/mem-postgres-memory.py



*Result*:
Title: Pdf Input Url
Link: https://docs.agno.com/examples/models/openai/responses/pdf_input_url
Content: Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.media import File
from agno.models.openai.responses import OpenAIResponses

# Setup the database for the Agent Session to be stored
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    db=db,
    tools=[{"type": "file_search"}, {"type": "web_search_preview"}],
    markdown=True,
)

agent.print_response(
    "Summarize the contents of the attached file and search the web for more information.",
    files=[File(url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf")],
)

# Get the stored Agent session, to check the response citations
session = agent.get_session()
if session and session.runs and session.runs[-1].citations:
    print("Citations:")
    print(session.runs[-1].citations)

Code
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.media import File
from agno.models.openai.responses import OpenAIResponses

# Setup the database for the Agent Session to be stored
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    db=db,
    tools=[{"type": "file_search"}, {"type": "web_search_preview"}],
    markdown=True,
)

agent.print_response(
    "Summarize the contents of the attached file and search the web for more information.",
    files=[File(url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf")],
)

# Get the stored Agent session, to check the response citations
session = agent.get_session()
if session and session.runs and session.runs[-1].citations:
    print("Citations:")
    print(session.runs[-1].citations)

Usage
Set your API key Install libraries Run Agent python cookbook/models/openai/responses/pdf_input_url.py



*Result*:
Title: Custom Table Names
Link: https://docs.agno.com/concepts/memory/overview
Content: You can specify a custom table name for storing memories: from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup your database
db = PostgresDb(
    db_url="postgresql://user:password@localhost:5432/my_database",
    memory_table="my_memory_table", # Specify the table to store memories
)

# Setup your Agent with the database
agent = Agent(db=db, enable_user_memories=True)

# Run the Agent. This will store a session in our "my_memory_table"
agent.print_response("Hi! My name is John Doe and I like to play basketball on the weekends.")

agent.print_response("What are my hobbies?")

Manual Memory Retrieval
While memories are automatically recalled during conversations, you can also manually retrieve them using the get_user_memories method. This is useful for debugging, displaying user profiles, or building custom memory interfaces: from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup your database
db = PostgresDb(
    db_url="postgresql://user:password@localhost:5432/my_database",
    memory_table="my_memory_table", # Specify the table to store memories
)

# Setup your Agent with the database
agent = Agent(db=db)

# Run the Agent. This will store a memory in our "my_memory_table"
agent.print_response("I love sushi!", user_id="123")

# Retrieve the memories about the user
memories = agent.get_user_memories(user_id="123")
print(memories)

Storage: Where Memories Live
Memories are stored in the database you connect to your agent. Agno supports all major database systems: Postgres, SQLite, MongoDB, and more. Check the Storage documentation for the full list of supported databases and setup instructions. By default, memories are stored in the agno_memories table (or collection, for document databases). If this table doesn't exist when your agent first tries to store a memory, Agno creates it automatically with no manual schema setup required.



*Result*:
Title: Storage
Link: https://docs.agno.com/how-to/v2-changelog
Content: Agent , Team , Workflow and the various evals now all support a single db parameter. This is to enable storage for the instance of that class. This is required for persistence of sessions, memories, metrics, etc. storage and memory have been removed from Agent , Team and Workflow. This means all previous storage providers have been reworked. Also session storage, memory storage and eval storage are all a single solution now referred to as a "DB". PostgresStorage -> PostgresDb SqliteStorage -> SqliteDb MysqlStorage -> MysqlDb RedisStorage -> RedisDb MongoStorage -> MongoDb DynamoDBStorage -> DynamoDb SingleStoreStorage -> SingleStoreDb InMemoryStorage -> InMemoryDb JsonStorage -> JsonDb GCSJsonStorage -> GCSJsonDb

Updates to  Classes
This means all previous storage providers have been reworked. Also session storage, memory storage and eval storage are all a single solution now referred to as a "DB". PostgresStorage  ->  PostgresDb SqliteStorage  ->  SqliteDb MysqlStorage  ->  MysqlDb RedisStorage  ->  RedisDb MongoStorage  ->  MongoDb DynamoDBStorage  ->  DynamoDb SingleStoreStorage  ->  SingleStoreDb InMemoryStorage  ->  InMemoryDb JsonStorage  ->  JsonDb GCSJsonStorage  ->  GCSJsonDb

Session & Run State
We have made significant changes to the innerworkings of Agent , Team and Workflow to make them completely stateless. This means that agent_session , session_metrics , session_state , etc. should not be seen as stateful variables that would be updated during the course of a run, but rather as "defaults" for the agent if they can be set on initialisation. CustomEvent is now supported and you can inherit from it to create your own custom events that can be yielded from your own tools. See the documentation for more details. For agents: RunResponse -> RunOutput RunResponseStartedEvent -> RunStartedEvent RunResponseContentEvent -> RunContentEvent RunResponseCompletedEvent -> RunCompletedEvent IntermediateRunResponseContentEvent -> IntermediateRunContentEvent RunResponseErrorEvent -> RunErrorEvent RunResponseCancelledEvent -> RunCancelledEvent For teams: TeamRunResponse -> TeamRunOutput RunResponseStartedEvent -> RunStartedEvent RunResponseContentEvent -> RunContentEvent RunResponseCompletedEvent -> RunCompletedEvent IntermediateRunResponseContentEvent -> IntermediateRunContentEvent RunResponseErrorEvent -> RunErrorEvent RunResponseCancelledEvent -> RunCancelledEvent For workflows: WorkflowRunResponse -> WorkflowRunOutput WorkflowRunResponseStartedEvent -> WorkflowRunStartedEvent WorkflowRunResponseContentEvent -> WorkflowRunContentEvent WorkflowRunResponseCompletedEvent -> WorkflowRunCompletedEvent WorkflowRunResponseErrorEvent -> WorkflowRunErrorEvent WorkflowRunResponseCancelledEvent -> WorkflowRunCancelledEvent The import location for RunOutput (and events) has been moved to agno.run.agent. For RunOutput , TeamRunOutput and WorkflowRunOutput the extra_data attribute has been removed and the internal attributes are now top-level. This is references , additional_input , reasoning_steps , and reasoning_messages. metadata added to RunOutput , TeamRunOutput and WorkflowRunOutput . This represents all the set metadata for the run. Session storage now stores AgentSession , TeamSession and WorkflowSession with new schemas. See full details in the Session section. Session objects now have runs directly on it. Session objects support new convenience methods: get_run -> Get a specific run by ID. get_session_summary -> Get the session summary. get_chat_history -> Get an aggregated view of all messages for all runs in the session. SessionMetrics and MessageMetrics have been unified as a single Metrics class. audio_tokens has been renamed to audio_total_tokens. input_audio_tokens has been renamed to audio_input_tokens. output_audio_tokens has been renamed to audio_output_tokens. cached_tokens has been renamed to cache_read_tokens. prompt_tokens and completion_tokens have been removed (only input_tokens and output_tokens should be used) prompt_tokens_details and completion_tokens_details have been removed. Instead provider_metrics captures any provider-specific metrics. time has been renamed to duration. You can now cancel a run by calling cancel_run on the Agent , Team or Workflow. This will cancel the run and return a RunCancelledEvent during streaming, or set the RunOutput.status to "cancelled".



*Result*:
Title: Postgres Tools
Link: https://docs.agno.com/examples/concepts/tools/database/postgres
Content: Code
from agno.agent import Agent
from agno.tools.postgres import PostgresTools

agent = Agent(
    tools=[PostgresTools(db_url="postgresql://user:pass@localhost:5432/db")],
        markdown=True,
)
agent.print_response("Show me all tables in the database")

Usage
Set your API key Set your database URL export DATABASE_URL=postgresql://user:pass@localhost:5432/db

Code
from agno.agent import Agent
from agno.tools.postgres import PostgresTools

agent = Agent(
    tools=[PostgresTools(db_url="postgresql://user:pass@localhost:5432/db")],
        markdown=True,
)
agent.print_response("Show me all tables in the database")



*Result*:
Title: PostgreSQL
Link: https://docs.agno.com/concepts/db/postgres
Content: Agno supports using PostgreSQL as a database with the PostgresDb class.

Usage
from agno.agent import Agent
from agno.db.postgres import PostgresDb

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai" # Replace with your own connection string

# Setup your Database
db = PostgresDb(db_url=db_url)

# Setup your Agent with the Database
agent = Agent(db=db)

Learn to use PostgreSQL as a database for your Agents



*Result*:
Title: Code
Link: https://docs.agno.com/examples/concepts/teams/session/session_summary_references
Content: """
This example shows how to use the `add_session_summary_to_context` parameter in the Team config to
add session summaries to the Team context.

Start the postgres db locally on Docker by running: cookbook/scripts/run_pgvector.sh
"""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
    enable_session_summaries=True,
)

# This will create a new session summary
team.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends.",
)

# You can use existing session summaries from session storage without creating or updating any new ones.
team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="session_summary",
    add_session_summary_to_context=True,
    members=[agent],
)

team.print_response("I also like to play basketball.")

# Alternatively, you can create a new session summary without adding the session summary to context.

# team = Team(
#     model=OpenAIChat(id="gpt-5-mini"),
#     db=db,
#     session_id="session_summary",
#     enable_session_summaries=True,
#     add_session_summary_to_context=False,
# )

# team.print_response("I also like to play basketball.")

Usage
Install required libraries Set environment variables Start PostgreSQL database Run the agent python cookbook/examples/teams/session/04_session_summary_references.py

Session Summary with Context References
This example shows how to use the add_session_summary_to_context parameter to add session summaries to team context for maintaining conversation continuity.



*Result*:
Title: Code
Link: https://docs.agno.com/examples/concepts/agent/session/01_persistent_session
Content: from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="session_storage",
    add_history_to_context=True,
)

agent.print_response("Tell me a new interesting fact about space")

Persistent Session Storage
This example demonstrates how to create an agent with persistent session storage using PostgreSQL, enabling conversation history to be maintained across different runs.

Persistent Session Storage
Persistent Session Storage
This example demonstrates how to create an agent with persistent session storage using PostgreSQL, enabling conversation history to be maintained across different runs.


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Perfect! I found the issue. Looking at the examples, the correct parameter is `session_table` not `table_name`. Also, for memory, it's `memory_table`. Let me fix this.

From the docs:
```python
db = PostgresDb(
    db_url=db_url,
    session_table="sessions"  # Not table_name!
)
```

And for memory:
```python
db = PostgresDb(
    db_url="postgresql://user:password@localhost:5432/my_database",
    memory_table="my_memory_table"
)
```</details></think>

---

Found the issue! The parameter is `session_table`, not `table_name`. Let me fix it:

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 2, lines removed: 1

```diff
@@ -52,6 +52,7 @@
  # Configure database for session and memory management
  db = PostgresDb(
-     table_name=&quot;agent_sessions&quot;,
      db_url=DB_URL,
+     session_table=&quot;agent_sessions&quot;,
+     memory_table=&quot;agent_memory&quot;,
  )
  
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Good! Now the PostgresDb parameters are correct. Let me test this by running it again.</details></think>

---

Perfect! Now try running it again:

```bash
python 04-agno-agentos.py
```

**Fixed:** Changed `table_name="agent_sessions"` to `session_table="agent_sessions"` and added `memory_table="agent_memory"` for proper PostgresDb initialization.

---

_**User (2025-11-06 20:41Z)**_

(.venv) 

ahmed@TheMountain MINGW64 /c/CodeWork/should-i-move (main)

$ python 04-agno-agentos.py 

âœ… Loaded 178 cities from database

Traceback (most recent call last):

  File "C:\CodeWork\should-i-move\04-agno-agentos.py", line 235, in <module>

    cost_analyst = Agent(

        name="Cost Analyst",

    ...<17 lines>...

        markdown=True,

    )

TypeError: Agent.__init__() got an unexpected keyword argument 'agent_id'

(.venv) 

ahmed@TheMountain MINGW64 /c/CodeWork/should-i-move (main)

$

---

_**Agent (model claude-4.5-sonnet-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The error shows that `agent_id` is not a valid parameter for `Agent.__init__()`. Let me check the official docs for the correct parameter name.</details></think>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_docs-agno_SearchAgno">
<details>
          <summary>Tool use: **mcp_docs-agno_SearchAgno**</summary>
      
*Called tool*: docs-agno - SearchAgno: Search across the Agno knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Agno, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation pages.

*Parameters*:
  * query: Agent init parameters id name agent_id

*Result*:
Title: AgentOS
Link: https://docs.agno.com/reference/agent-os/agent-os
Content: Parameters
Parameter Type Default Description id Optional[str] Autogenerated UUID AgentOS ID name Optional[str] None AgentOS name description Optional[str] None AgentOS description version Optional[str] None AgentOS version agents Optional[List[Agent]] None List of agents available in the AgentOS teams Optional[List[Team]] None List of teams available in the AgentOS workflows Optional[List[Workflow]] None List of workflows available in the AgentOS knowledge Optional[List[Knowledge]] None List of standalone knowledge instances available in the AgentOS interfaces Optional[List[BaseInterface]] None List of interfaces available in the AgentOS config Optional[Union[str, AgentOSConfig]] None User-provided configuration for the AgentOS. Either a path to a YAML file or an AgentOSConfig instance. settings Optional[AgnoAPISettings] None Settings for the AgentOS API base_app Optional[FastAPI] None Custom FastAPI APP to use for the AgentOS lifespan Optional[Any] None Lifespan context manager for the FastAPI app enable_mcp_server bool False Whether to enable MCP (Model Context Protocol) on_route_conflict Literal["preserve_agentos", "preserve_base_app", "error"] "preserve_agentos" What to do when a route conflict is detected in case a custom base_app is provided. telemetry bool True Log minimal telemetry for analytics

Parameters
Parameter Type Default Description id Optional[str] Autogenerated UUID  ID name Optional[str] None AgentOS name description Optional[str] None AgentOS description version Optional[str] None AgentOS version agents Optional[List[Agent]] None List of agents available in the AgentOS teams Optional[List[Team]] None List of teams available in the AgentOS workflows Optional[List[Workflow]] None List of workflows available in the AgentOS knowledge Optional[List[Knowledge]] None List of standalone knowledge instances available in the AgentOS interfaces Optional[List[BaseInterface]] None List of interfaces available in the AgentOS config Optional[Union[str, AgentOSConfig]] None User-provided configuration for the AgentOS. Either a path to a YAML file or an AgentOSConfig instance. settings Optional[AgnoAPISettings] None Settings for the AgentOS API base_app Optional[FastAPI] None Custom FastAPI APP to use for the AgentOS lifespan Optional[Any] None Lifespan context manager for the FastAPI app enable_mcp_server bool False Whether to enable MCP (Model Context Protocol) on_route_conflict Literal["preserve_agentos", "preserve_base_app", "error"] "preserve_agentos" What to do when a route conflict is detected in case a custom base_app is provided. telemetry bool True Log minimal telemetry for analytics

serve
Run the app, effectively starting the . Parameters: app (Union[str, FastAPI]): FastAPI APP instance host (str): Host to bind. Defaults to localhost port (int): Port to bind. Defaults to 7777 workers (Optional[int]): Number of workers to use. Defaults to None reload (bool): Enable auto-reload for development. Defaults to False



*Result*:
Title: AgentOS Parameters
Link: https://docs.agno.com/agent-os/customize/os/attributes
Content: You can configure the behaviour of your AgentOS by passing the following parameters to the AgentOS class: agents : List of agents to include in the AgentOS teams : List of teams to include in the AgentOS workflows : List of workflows to include in the AgentOS knowledge : List of knowledge instances to include in the AgentOS interfaces : List of interfaces to include in the AgentOS See the Interfaces section for more details. config : Configuration file path or AgentOSConfig instance See the Configuration page for more details. base_app : Optional custom FastAPI app to use instead of creating a new one See the Custom FastAPI App page for more details. lifespan : Optional lifespan context manager for the FastAPI app See the Lifespan page for more details. enable_mcp_server : Turn your AgentOS into an MCP server See the MCP enabled AgentOS page for more details. on_route_conflict : Optionally preserve your custom routes over AgentOS routes (set to "preserve_base_app" ). Defaults to "preserve_agentos" , preserving the AgentOS routes See the Overriding Routes page for more details. See the AgentOS class reference for more details.

Learn about the attributes of the AgentOS class



*Result*:
Title: Agent
Link: https://docs.agno.com/reference/agents/agent
Content: Parameters
Parameter Type Default Description model Optional[Union[Model, str]] None Model to use for this Agent. Can be a Model object or a model string ( provider:model_id) name Optional[str] None Agent name id Optional[str] None Agent ID (autogenerated UUID if not set) user_id Optional[str] None Default user_id to use for this agent session_id Optional[str] None Default session_id to use for this agent (autogenerated if not set) session_state Optional[Dict[str, Any]] None Default session state (stored in the database to persist across runs) add_session_state_to_context bool False Set to True to add the session_state to the context enable_agentic_state bool False Set to True to give the agent tools to update the session_state dynamically overwrite_db_session_state bool False Set to True to overwrite the session state in the database with the session state provided in the run cache_session bool False If True, cache the current Agent session in memory for faster access search_session_history Optional[bool] False Set this to True to allow searching through previous sessions. num_history_sessions Optional[int] None Specify the number of past sessions to include in the search. It's advisable to keep this number to 2 or 3 for now, as a larger number might fill up the context length of the model, potentially leading to performance issues. dependencies Optional[Dict[str, Any]] None Dependencies available for tools and prompt functions add_dependencies_to_context bool False If True, add the dependencies to the user prompt db Optional[BaseDb] None Database to use for this agent memory_manager Optional[MemoryManager] None Memory manager to use for this agent enable_agentic_memory bool False Enable the agent to manage memories of the user enable_user_memories bool False If True, the agent creates/updates user memories at the end of runs add_memories_to_context Optional[bool] None If True, the agent adds a reference to the user memories in the response enable_session_summaries bool False If True, the agent creates/updates session summaries at the end of runs add_session_summary_to_context Optional[bool] None If True, the agent adds session summaries to the context session_summary_manager Optional[SessionSummaryManager] None Session summary manager add_history_to_context bool False Add the chat history of the current session to the messages sent to the Model num_history_runs Optional[int] None Number of historical runs to include in the messages. num_history_messages Optional[int] None Number of historical messages to include messages list sent to the Model. knowledge Optional[Knowledge] None Agent Knowledge knowledge_filters Optional[Dict[str, Any]] None Knowledge filters to apply to the knowledge base enable_agentic_knowledge_filters Optional[bool] None Let the agent choose the knowledge filters add_knowledge_to_context bool False Enable RAG by adding references from Knowledge to the user prompt knowledge_retriever Optional[Callable[..., Optional[List[Union[Dict, str]]]]] None Function to get references to add to the user_message references_format Literal["json", "yaml"] "json" Format of the references metadata Optional[Dict[str, Any]] None Metadata stored with this agent tools Optional[List[Union[Toolkit, Callable, Function, Dict]]] None A list of tools provided to the Model tool_call_limit Optional[int] None Maximum number of tool calls allowed for a single run tool_choice Optional[Union[str, Dict[str, Any]]] None Controls which (if any) tool is called by the model max_tool_calls_from_history Optional[int] None Maximum number of tool calls from history to keep in context. If None, all tool calls from history are included. If set to N, only the last N tool calls from history are added to the context for memory management tool_hooks Optional[List[Callable]] None Functions that will run between tool calls pre_hooks Optional[Union[List[Callable[..., Any]], List[BaseGuardrail]]] None Functions called right after agent-session is loaded, before processing starts post_hooks Optional[Union[List[Callable[..., Any]], List[BaseGuardrail]]] None Functions called after output is generated but before the response is returned reasoning bool False Enable reasoning by working through the problem step by step reasoning_model Optional[Union[Model, str]] None Model to use for reasoning. Can be a Model object or a model string ( provider:model_id) reasoning_agent Optional[Agent] None Agent to use for reasoning reasoning_min_steps int 1 Minimum number of reasoning steps reasoning_max_steps int 10 Maximum number of reasoning steps read_chat_history bool False Add a tool that allows the Model to read the chat history search_knowledge bool True Add a tool that allows the Model to search the knowledge base update_knowledge bool False Add a tool that allows the Model to update the knowledge base read_tool_call_history bool False Add a tool that allows the Model to get the tool call history send_media_to_model bool True If False, media (images, videos, audio, files) is only available to tools and not sent to the LLM store_media bool True If True, store media in the database store_tool_messages bool True If True, store tool results in the database store_history_messages bool True If True, store history messages in the database system_message Optional[Union[str, Callable, Message]] None Provide the system message as a string or function system_message_role str "system" Role for the system message build_context bool True Set to False to skip context building description Optional[str] None A description of the Agent that is added to the start of the system message instructions Optional[Union[str, List[str], Callable]] None List of instructions for the agent expected_output Optional[str] None Provide the expected output from the Agent additional_context Optional[str] None Additional context added to the end of the system message markdown bool False If markdown=true, add instructions to format the output using markdown add_name_to_context bool False If True, add the agent name to the instructions add_datetime_to_context bool False If True, add the current datetime to the instructions to give the agent a sense of time add_location_to_context bool False If True, add the current location to the instructions to give the agent a sense of place timezone_identifier Optional[str] None Allows for custom timezone for datetime instructions following the TZ Database format (e.g. "Etc/UTC") resolve_in_context bool True If True, resolve session_state, dependencies, and metadata in the user and system messages additional_input Optional[List[Union[str, Dict, BaseModel, Message]]] None A list of extra messages added after the system message and before the user message user_message_role str "user" Role for the user message build_user_context bool True Set to False to skip building the user context retries int 0 Number of retries to attempt delay_between_retries int 1 Delay between retries (in seconds) exponential_backoff bool False If True, the delay between retries is doubled each time input_schema Optional[Type[BaseModel]] None Provide an input schema to validate the input output_schema Optional[Type[BaseModel]] None Provide a response model to get the response as a Pydantic model parser_model Optional[Union[Model, str]] None Provide a secondary model to parse the response from the primary model. Can be a Model object or a model string ( provider:model_id) parser_model_prompt Optional[str] None Provide a prompt for the parser model output_model Optional[Union[Model, str]] None Provide an output model to structure the response from the main model. Can be a Model object or a model string ( provider:model_id) output_model_prompt Optional[str] None Provide a prompt for the output model parse_response bool True If True, the response from the Model is converted into the output_schema structured_outputs Optional[bool] None Use model enforced structured_outputs if supported (e.g. OpenAIChat) use_json_mode bool False If output_schema is set, sets the response mode of the model, i.e. if the model should explicitly respond with a JSON object instead of a Pydantic model save_response_to_file Optional[str] None Save the response to a file stream Optional[bool] None Stream the response from the Agent stream_events bool False Stream the intermediate steps from the Agent store_events bool False Persist the events on the run response events_to_skip Optional[List[RunEvent]] None Specify which event types to skip when storing events on the RunOutput role Optional[str] None If this Agent is part of a team, this is the role of the agent in the team debug_mode bool False Enable debug logs debug_level Literal[1, 2] 1 Debug level for logging telemetry bool True Log minimal telemetry for analytics

set_session_name
Set the session name. Parameters: session_id (str): Session ID to use autogenerate (bool): Whether to autogenerate the name session_name (Optional[str]): The name to set Returns: Session : The updated session

rename
Rename the agent and update the session. Parameters: name (str): The new name for the agent session_id (str): Session ID to use



*Result*:
Title: AgentSession
Link: https://docs.agno.com/reference/agents/session
Content: AgentSession Attributes
Parameter Type Default Description session_id str Required Session UUID agent_id Optional[str] None ID of the agent that this session is associated with team_id Optional[str] None ID of the team that this session is associated with user_id Optional[str] None ID of the user interacting with this agent workflow_id Optional[str] None ID of the workflow that this session is associated with session_data Optional[Dict[str, Any]] None Session Data: session_name, session_state, images, videos, audio metadata Optional[Dict[str, Any]] None Metadata stored with this agent agent_data Optional[Dict[str, Any]] None Agent Data: agent_id, name and model runs Optional[List[RunOutput]] None List of all runs in the session summary Optional[SessionSummary] None Summary of the session created_at Optional[int] None The unix timestamp when this session was created updated_at Optional[int] None The unix timestamp when this session was last updated

Attributes
Parameter Type Default Description session_id str Required Session UUID agent_id Optional[str] None ID of the agent that this session is associated with team_id Optional[str] None ID of the team that this session is associated with user_id Optional[str] None ID of the user interacting with this agent workflow_id Optional[str] None ID of the workflow that this session is associated with session_data Optional[Dict[str, Any]] None Session Data: session_name, session_state, images, videos, audio metadata Optional[Dict[str, Any]] None Metadata stored with this agent agent_data Optional[Dict[str, Any]] None Agent Data: agent_id, name and model runs Optional[List[RunOutput]] None List of all runs in the session summary Optional[SessionSummary] None Summary of the session created_at Optional[int] None The unix timestamp when this session was created updated_at Optional[int] None The unix timestamp when this session was last updated

get_messages_from_last_n_runs(...) -> List[Message]
Gets messages from the last N runs with various filtering options: agent_id : Filter by agent ID team_id : Filter by team ID last_n : Number of recent runs to include skip_role : Skip messages with specific role skip_status : Skip runs with specific statuses skip_history_messages : Whether to skip history messages



*Result*:
Title: Agent with Output Model
Link: https://docs.agno.com/examples/concepts/agent/input_and_output/output_model
Content: Agent with Output Model
This example demonstrates how to use the output_model parameter to specify a different model for generating the final response, enabling model switching during agent execution.

This example demonstrates how to use the output_model parameter to specify a different model for generating the final response, enabling model switching during agent execution.

Code
"""
This example shows how to use the output_model parameter to specify the model that will be used to generate the final response.
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-4.1"),
    output_model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
)

agent.print_response("Latest news from France?", stream=True)



*Result*:
Title: Configuration Options
Link: https://docs.agno.com/integrations/observability/openlit
Content: The openlit.init() function accepts several parameters: openlit.init(
    otlp_endpoint="http://127.0.0.1:4318",  # OTLP collector endpoint
    tracer=None,  # Custom OpenTelemetry tracer
    disable_batch=False,  # Disable batch span processing
    environment="production",  # Environment name for filtering
    application_name="my-agent",  # Application identifier
)

Example: Basic Agent Setup
This example demonstrates how to instrument your Agno agent with OpenLIT for automatic tracing. import openlit
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools

# Initialize OpenLIT instrumentation
openlit.init(
    otlp_endpoint="http://127.0.0.1:4318"  # Your OpenLIT OTLP endpoint
)

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True)],
    instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
    show_tool_calls=True,
)

# Use the agent - all calls are automatically traced
agent.print_response("What is the current price of Tesla and what do analysts recommend?")

Example: Development Mode (Console Output)
For local development without a collector, OpenLIT can output traces directly to the console: import openlit
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Initialize OpenLIT without OTLP endpoint for console output
openlit.init()

# Create and configure the agent
agent = Agent(
    name="Web Search Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Search the web and provide comprehensive answers.",
    markdown=True,
)

# Use the agent - traces will be printed to console
agent.print_response("What are the latest developments in AI agents?")



*Result*:
Title: Passing agent parameters
Link: https://docs.agno.com/agent-os/api
Content: Agent, Team and Workflow run() and arun() endpoints all support additional parameters. See the Agent arun schema , Team arun schema , Workflow arun schema for more details. To pass these parameters to your agent, team or workflow, via the AgentOS API, you can simply specify them as form-based parameters. Below is an example where dependencies are passed to the agent: from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.os import AgentOS

# Setup the database
db = PostgresDb(id="basic-db", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

# Setup basic agents, teams and workflows
story_writer = Agent(
    id="story-writer-agent",
    name="Story Writer Agent",
    db=db,
    markdown=True,
    instructions="You are a story writer. You are asked to write a story about a robot. Always name the robot {robot_name}",
)

# Setup our AgentOS app
agent_os = AgentOS(
    description="Example AgentOS to show how to pass dependencies to an agent",
    agents=[story_writer],
)
app = agent_os.get_app()


if __name__ == "__main__":
    agent_os.serve(app="dependencies_to_agent:app", reload=True)

Agent, Team and Workflow run() and arun() endpoints all support additional parameters. See the Agent arun schema , Team arun schema , Workflow arun schema for more details. To pass these parameters to your agent, team or workflow, via the AgentOS API, you can simply specify them as form-based parameters. Below is an example where dependencies are passed to the agent: Then to test it, you can run the following command: curl --location 'http://localhost:7777/agents/story-writer-agent/runs' \
    --header 'Content-Type: application/x-www-form-urlencoded' \
    --data-urlencode 'message=Write me a 5 line story.' \
    --data-urlencode 'dependencies={"robot_name": "Anna"}'

Agent, Team and Workflow run() and arun() endpoints all support additional parameters. See the Agent arun schema , Team arun schema , Workflow arun schema for more details. To pass these parameters to your agent, team or workflow, via the AgentOS API, you can simply specify them as form-based parameters. Below is an example where dependencies are passed to the agent: Then to test it, you can run the following command:



*Result*:
Title: Agent with Vertex AI
Link: https://docs.agno.com/examples/models/gemini/vertexai
Content: Code
"""
To use Vertex AI, with the Gemini Model class, you need to set the following environment variables:

export GOOGLE_GENAI_USE_VERTEXAI="true"
export GOOGLE_CLOUD_PROJECT="your-project-id"
export GOOGLE_CLOUD_LOCATION="your-location"

Or you can set the following parameters in the `Gemini` class:

gemini = Gemini(
    vertexai=True,
    project_id="your-google-cloud-project-id",
    location="your-google-cloud-location",
)
"""

from agno.agent import Agent, RunOutput  # noqa
from agno.models.google import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-001"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

Code
"""
To use Vertex AI, with the Gemini Model class, you need to set the following environment variables:

export GOOGLE_GENAI_USE_VERTEXAI="true"
export GOOGLE_CLOUD_PROJECT="your-project-id"
export GOOGLE_CLOUD_LOCATION="your-location"

Or you can set the following parameters in the `Gemini` class:

gemini = Gemini(
    vertexai=True,
    project_id="your-google-cloud-project-id",
    location="your-google-cloud-location",
)
"""

from agno.agent import Agent, RunOutput  # noqa
from agno.models.google import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-001"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

Usage
Set up Vertex AI Set your environment variables: Or configure in code: gemini = Gemini(
    vertexai=True,
    project_id="your-google-cloud-project-id",
    location="your-google-cloud-location",
)



*Result*:
Title: Basic Agent
Link: https://docs.agno.com/examples/models/ibm/basic
Content: Code
from agno.agent import Agent, RunOutput
from agno.models.ibm import WatsonX

agent = Agent(model=WatsonX(id="ibm/granite-20b-code-instruct"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

Code
from agno.agent import Agent, RunOutput
from agno.models.ibm import WatsonX

agent = Agent(model=WatsonX(id="ibm/granite-20b-code-instruct"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

Usage
Set your API key Install libraries Run Agent This example creates an agent using the IBM WatsonX model and prints a response directly to the terminal. The markdown=True parameter tells the agent to format the output as markdown, which can be useful for displaying rich text content.



*Result*:
Title: Agent State
Link: https://docs.agno.com/concepts/agents/state
Content: Your Agents often need to access certain data during a run/session. It could be a todo list, the user's profile, or anything else. When this data needs to remain accessible across runs, or needs to be updated during the session, you want to consider it session state. Session state is accessible from tool calls, pre-hooks and post-hooks, and other functions that are part of the Agent run. You are also able to use it in the system message, to ultimately present it to the Model. Session state is also persisted in the database, if one is available to the Agent, and is automatically loaded when the session is continued. Understanding Agent "Statelessness" : Agents in Agno don't maintain working state directly on the Agent object in memory. Instead they provide state management capabilities: The session.get_session_state(session_id=session_id) method retrieves the session state of a particular session from the database The session_state parameter on Agent provides the default state data for new sessions Working state is managed per run and persisted to the database per session The agent instance (or attributes thereof) itself is not modified during runs

Agentic Session State
Agno provides a way to allow the Agent to automatically update the session state. Simply set the enable_agentic_state parameter to True. from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb

agent = Agent(
    db=SqliteDb(db_file="tmp/agents.db"),
    model=OpenAIChat(id="gpt-5-mini"),
    session_state={"shopping_list": []},
    add_session_state_to_context=True,  # Required so the agent is aware of the session state
    enable_agentic_state=True,  # Adds a tool to manage the session state
)

agent.print_response("Add milk, eggs, and bread to the shopping list", stream=True)
print(f"Session state: {agent.get_session_state()}")

Using state in instructions
You can reference variables from the session state in your instructions. Don't use the f-string syntax in the instructions. Directly use the {key} syntax, Agno substitutes the values for you. from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb


agent = Agent(
    db=SqliteDb(db_file="tmp/agents.db"),
    model=OpenAIChat(id="gpt-5-mini"),
    # Initialize the session state with a variable
    session_state={"user_name": "John"},
    # You can use variables from the session state in the instructions
    instructions="Users name is {user_name}",
    markdown=True,
)

agent.print_response("What is my name?", stream=True)


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I found it! Looking at the Agent reference documentation, the parameter is `id`, not `agent_id`. The official docs show:

```python
agent = Agent(
    id="story-writer-agent",  # <-- This is the correct parameter
    name="Story Writer Agent",
    ...
)
```

I need to change `agent_id` to `id` for all three agents and the team.</details></think>

---

Found it! The parameter is `id`, not `agent_id`. Let me fix all the agents and the team:

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -235,5 +235,5 @@
  cost_analyst = Agent(
      name=&quot;Cost Analyst&quot;,
-     agent_id=&quot;cost-analyst&quot;,  # Unique ID for AgentOS
+     id=&quot;cost-analyst&quot;,  # Unique ID for AgentOS
      model=OpenAIChat(&quot;gpt-4o-mini&quot;),
      role=&quot;Analyzes cost of living differences between cities&quot;,
```

</details>

</tool-use>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -257,5 +257,5 @@
  sentiment_analyst = Agent(
      name=&quot;Sentiment Analyst&quot;,
-     agent_id=&quot;sentiment-analyst&quot;,  # Unique ID for AgentOS
+     id=&quot;sentiment-analyst&quot;,  # Unique ID for AgentOS
      model=OpenAIChat(&quot;gpt-4o-mini&quot;),
      role=&quot;Researches city vibe, culture, and livability&quot;,
```

</details>

</tool-use>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -278,5 +278,5 @@
  migration_researcher = Agent(
      name=&quot;Migration Researcher&quot;,
-     agent_id=&quot;migration-researcher&quot;,  # Unique ID for AgentOS
+     id=&quot;migration-researcher&quot;,  # Unique ID for AgentOS
      model=OpenAIChat(&quot;gpt-4o-mini&quot;),
      role=&quot;Finds and summarizes experiences from people who made similar moves&quot;,
```

</details>

</tool-use>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **code_edit** â€¢ Edit file: 04-agno-agentos.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -306,5 +306,5 @@
  move_decision_team = Team(
      name=&quot;City Move Decision Team&quot;,
-     team_id=&quot;move-decision-team&quot;,  # Unique ID for AgentOS
+     id=&quot;move-decision-team&quot;,  # Unique ID for AgentOS
      model=OpenAIChat(&quot;gpt-4o-mini&quot;),
      members=[cost_analyst, sentiment_analyst, migration_researcher],
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Good! I've fixed all the `agent_id` and `team_id` to `id`. Now the script should work.</details></think>

---

Perfect! Now try running it again:

```bash
python 04-agno-agentos.py
```

**Fixed:** Changed all instances of `agent_id` and `team_id` to `id` to match the official Agno API.

---


<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session 52ffcd7c-ccf8-48aa-a48b-090950e88231 (2026-01-26 20:40Z) -->

# New sub-agent ideas (2026-01-26 20:40Z)

_**User (2026-01-26 20:27Z)**_

what might be another sub-agent I could task students with adding to this application?

---

_**Agent (model gemini-3-pro-preview, mode Ask)**_

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** ‚Ä¢ Read file: agno-coordinator.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** ‚Ä¢ Read file: sub_agents/migration_researcher/tools.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** ‚Ä¢ Read file: sub_agents/cost_analyst/tools.py</summary>

</details>
</tool-use>

---

Based on the current architecture, the application covers **Financials** (`cost_analyst`), **Social Sentiment** (`sentiment_analyst`), and **Migration Logistics** (`migration_researcher`).

A great addition for students to build would be a **Lifestyle & Amenities Analyst**.

This agent would focus on the *hard data* of living there: "Are there good parks?", "How many coffee shops are there?", "Is it walkable?", or "What is the weather like?"

### Proposal: The Lifestyle & Amenities Analyst

**Goal:** Quantify the quality of life based on specific points of interest (POIs) and infrastructure.

**Why it's good for students:**
1.  **Distinct Responsibility:** It doesn't overlap with cost or general "vibes."
2.  **API Practice:** It requires working with structured data (unlike the text-heavy Reddit search).
3.  **Scalable Difficulty:**
    *   *Level 1:* Mock the data (return hardcoded lists of gyms/parks).
    *   *Level 2:* Use a free API like **OpenStreetMap (Nominatim)** to count actual locations.
    *   *Level 3:* Use **Google Places API** to get ratings and reviews of local spots.

---

### Implementation Plan for Students

Here is the roadmap you can give your students to add this agent.

#### Step 1: Create the Directory Structure
Create a new folder `sub_agents/lifestyle_analyst/` and add `__init__.py`, `agent.py`, and `tools.py`.

#### Step 2: Create the Tools (`sub_agents/lifestyle_analyst/tools.py`)
This tool searches for specific amenities. For a classroom setting, using `duckduckgo` or a simple `requests` call to OpenStreetMap is easier than setting up Google Cloud keys.

```python
import requests

def search_amenities(city: str, amenity_type: str) -> str:
    """
    Searches for specific amenities in a city using OpenStreetMap (Nominatim).
    
    Args:
        city: The city to search in (e.g., "Austin, TX")
        amenity_type: The type of amenity (e.g., "cafe", "park", "gym")
        
    Returns:
        A summary string of found amenities.
    """
    print(f"üîé Searching for {amenity_type} in {city}...")
    
    # OpenStreetMap Nominatim API (Free, no key required for low volume)
    base_url = "https://nominatim.openstreetmap.org/search"
    params = {
        "q": f"{amenity_type} in {city}",
        "format": "json",
        "limit": 5
    }
    headers = {'User-Agent': 'StudentCityApp/1.0'}
    
    try:
        response = requests.get(base_url, params=params, headers=headers)
        data = response.json()
        
        if not data:
            return f"No {amenity_type}s found in {city}."
            
        results = [f"- {item['display_name']}" for item in data]
        return f"Found {len(data)} top results for {amenity_type} in {city}:\n" + "\n".join(results)
        
    except Exception as e:
        return f"Error searching for amenities: {str(e)}"
```

#### Step 3: Create the Agent (`sub_agents/lifestyle_analyst/agent.py`)
Define the agent and give it a specific personality‚Äîperhaps an "Urban Planner" or "Digital Nomad."

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from .tools import search_amenities

lifestyle_analyst = Agent(
    name="Lifestyle Analyst",
    role="Urban Living Specialist",
    model=OpenAIChat("gpt-4o-mini"),
    tools=[search_amenities],
    instructions=[
        "You are an expert on city amenities and quality of life.",
        "When asked about a city, look for key indicators of a good lifestyle:",
        "1. Coffee shops (for remote work/socializing)",
        "2. Parks (for outdoor access)",
        "3. Gyms (for health)",
        "Use the search_amenities tool to find real examples.",
        "Summarize the 'vibe' based on the density and type of amenities found."
    ],
    show_tool_calls=True,
    markdown=True,
)
```

#### Step 4: Register in the Coordinator (`agno-coordinator.py`)
Students need to wire this new agent into the main team.

1.  **Import it:**
    ```python
    from sub_agents.lifestyle_analyst.agent import lifestyle_analyst
    ```

2.  **Add to Team:**
    Update the `move_decision_team` definition:
    ```python
    move_decision_team = Team(
        # ... existing config ...
        members=[cost_analyst, sentiment_analyst, migration_researcher, lifestyle_analyst],
        # ...
    )
    ```

3.  **Update Instructions:**
    Update the coordinator's instructions to delegate to the new analyst:
    ```python
    # ... inside instructions list ...
    "  - Then, delegate to the Lifestyle Analyst to check for amenities like parks and cafes",
    # ...
    ```

### Alternative Ideas
If "Lifestyle" doesn't fit your curriculum, here are two other options:

1.  **Job Market Analyst:**
    *   *Task:* Search for "Software Engineer jobs in [City]" using a search tool.
    *   *Focus:* Economic viability beyond just cost of living.

2.  **Safety & Crime Analyst:**
    *   *Task:* Look up crime rates or safety scores.
    *   *Focus:* Risk assessment (though this can be depressing data to work with).

---

_**User (2026-01-26 20:27Z)**_

what might be a good dataset to use brave against? 

---

_**Agent (model gemini-3-pro-preview, mode Ask)**_

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** ‚Ä¢ Read file: sub_agents/sentiment_analyst/agent.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** ‚Ä¢ Read file: sub_agents/cost_analyst/tools.py</summary>

</details>
</tool-use>

---

A great "dataset" to target with Brave Search is **City-Data.com**.

While you are already using Reddit (which skews younger/renter), **City-Data** forums are a massive repository of discussions that often skew towards homeowners, families, and long-term residents. It is effectively a "dataset" of millions of relocation discussions.

Other good options include **Niche.com** (for school/neighborhood ratings) or **TripAdvisor** (for amenities), but City-Data is the most text-rich for an LLM to analyze.

### Proposal: Add `CityDataSearch` to the Sentiment Analyst

Currently, your `sentiment_analyst` has no tools and relies only on "general knowledge." Adding this tool will give it real, ground-truth data about safety, neighborhoods, and local vibes.

#### 1. Create the Tool
You can add this function to `sub_agents/sentiment_analyst/tools.py` (you'll need to create this file). It uses the same pattern as your Reddit search but targets the `forum` subdomain of City-Data.

```python
import os
import requests
from typing import Optional

def search_city_data_forums(city: str, state: str = "") -> str:
    """
    Searches City-Data.com forums for discussions about living in a specific city.
    Useful for finding info on safety, neighborhoods, and demographics.
    
    Args:
        city: The city name (e.g. "Austin")
        state: Optional state code (e.g. "TX") to refine search
    """
    api_key = os.getenv('BRAVE_API_KEY')
    if not api_key:
        return "Error: BRAVE_API_KEY not found."

    # Construct a targeted query
    # "site:city-data.com/forum" restricts results to the forum discussions
    location_query = f"{city} {state}".strip()
    query = f"site:city-data.com/forum {location_query} relocation safety neighborhoods"

    print(f"üîé Searching City-Data forums for: {location_query}...")

    try:
        response = requests.get(
            "https://api.search.brave.com/res/v1/web/search",
            params={"q": query, "count": 5},
            headers={"X-Subscription-Token": api_key}
        )
        
        data = response.json()
        results = data.get("web", {}).get("results", [])
        
        if not results:
            return "No discussions found on City-Data."

        # Format the output for the LLM
        formatted_results = "City-Data Forum Discussions:\n\n"
        for item in results:
            formatted_results += f"- Title: {item['title']}\n"
            formatted_results += f"  Snippet: {item['description']}\n"
            formatted_results += f"  Link: {item['url']}\n\n"
            
        return formatted_results

    except Exception as e:
        return f"Error searching City-Data: {str(e)}"
```

#### 2. Register it with the Agent
Update `sub_agents/sentiment_analyst/agent.py` to use this new tool.

```python
# ... existing imports ...
from .tools import search_city_data_forums  # Import the new tool

sentiment_analyst = Agent(
    name="Sentiment Analyst",
    # ... existing config ...
    tools=[search_city_data_forums],  # Add tool here
    instructions=[
        "Analyze the overall vibe and culture of the destination city",
        "Use the search_city_data_forums tool to find what locals say about safety and neighborhoods.",
        "Assess livability based on the user's preferences",
        # ...
    ],
    # ...
)
```

### Why this is a good teaching moment
1.  **Search Operators:** It teaches students the power of the `site:` operator. Instead of building a complex scraper for a specific site, they can just ask a search engine to index it for them.
2.  **Demographic Bias:** You can discuss how different "datasets" (Reddit vs. City-Data) yield different perspectives on the same city.

---

_**User (2026-01-26 20:27Z)**_

what if we did something like a news search. 

Use brave to look up news articles then use newspaper4k

---

_**Agent (model gemini-3-pro-preview, mode Ask)**_

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** ‚Ä¢ Read file: requirements.txt</summary>

</details>
</tool-use>

---

This is a fantastic idea. Using **Brave Search** to find recent articles and **newspaper4k** to extract the content allows the agent to read "local news" just like a resident would.

This gives the **Sentiment Analyst** the ability to detect:
*   Recent crime spikes or safety concerns.
*   New infrastructure projects (e.g., "New subway line opening").
*   Local political or economic issues.

Here is the plan to implement this for your students.

### Prerequisites

You will need to add `newspaper4k` to your project.

```bash
pip install newspaper4k
```

### Step 1: Create the News Tool
Create a new file: `sub_agents/sentiment_analyst/tools.py`.

This tool performs a two-step process:
1.  **Search:** Asks Brave for "latest news in [City]".
2.  **Scrape:** Uses `newspaper` to download the actual article text so the LLM can read it (instead of just seeing the headline).

```python
import os
import requests
from newspaper import Article
from typing import List

def get_city_news(city_name: str, max_articles: int = 3) -> str:
    """
    Searches for recent news about a city and extracts article content.
    
    Args:
        city_name: The city to search for (e.g. "San Francisco")
        max_articles: Number of articles to read (default: 3)
        
    Returns:
        A summary string containing headlines and article excerpts.
    """
    api_key = os.getenv('BRAVE_API_KEY')
    if not api_key:
        return "Error: BRAVE_API_KEY not found."

    # 1. Search for news URLs
    print(f"üì∞ Searching for latest news in {city_name}...")
    query = f"latest news {city_name} local news"
    
    try:
        response = requests.get(
            "https://api.search.brave.com/res/v1/web/search",
            params={"q": query, "count": 5, "search_lang": "en"},
            headers={"X-Subscription-Token": api_key}
        )
        data = response.json()
        results = data.get("web", {}).get("results", [])
    except Exception as e:
        return f"Error searching news: {str(e)}"

    if not results:
        return f"No news found for {city_name}."

    # 2. Extract content using newspaper4k
    output = f"### Latest Local News for {city_name}\n\n"
    
    articles_processed = 0
    for result in results:
        if articles_processed >= max_articles:
            break
            
        url = result.get('url')
        title = result.get('title')
        
        # Skip non-news sites or paywalls if obvious (simple filter)
        if "reddit.com" in url or "youtube.com" in url:
            continue
            
        print(f"   üìÑ Reading: {title[:30]}...")
        
        try:
            article = Article(url)
            article.download()
            article.parse()
            
            # Add to output
            output += f"#### {title}\n"
            output += f"**Source:** {url}\n"
            # Get first 500 characters of text to save tokens
            snippet = article.text[:500].replace('\n', ' ') + "..."
            output += f"**Excerpt:** {snippet}\n\n"
            
            articles_processed += 1
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Failed to read {url}: {e}")
            continue

    return output
```

### Step 2: Update the Sentiment Analyst
Modify `sub_agents/sentiment_analyst/agent.py` to use this new tool.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from sub_agents.schemas import SentimentAnalysis
# Import the new tool
from .tools import get_city_news

sentiment_analyst = Agent(
    name="Sentiment Analyst",
    model=OpenAIChat("gpt-4o-mini"),
    role="Researches city vibe, culture, and livability",
    # Add the tool to the list
    tools=[get_city_news], 
    description=(
        "You are a city culture and livability expert. "
        "Research and analyze the general vibe, culture, and livability of the destination city. "
        "Use the get_city_news tool to find current events that might impact a decision to move."
    ),
    instructions=[
        "Analyze the overall vibe and culture of the destination city",
        "Use get_city_news to check for recent developments, crime, or local issues",
        "Assess livability based on the user's preferences",
        "Identify notable pros and cons based on both general knowledge and recent news",
        "Provide insights on how well the city matches user preferences",
    ],
    output_schema=SentimentAnalysis,
    markdown=True,
)
```

### Why this is powerful for students
1.  **"RAG" Concepts:** This introduces the concept of Retrieval-Augmented Generation (RAG) in a simple way‚Äîfetching external context (news) to ground the AI's answer.
2.  **Handling Noise:** Real web scraping is messy. Students will see that `newspaper4k` sometimes fails on paywalls or complex sites, teaching them about error handling in data pipelines.
3.  **Token Management:** By truncating the article text (`article.text[:500]`), you teach them about context window limits‚Äîwe don't need the whole article, just the gist.

---

